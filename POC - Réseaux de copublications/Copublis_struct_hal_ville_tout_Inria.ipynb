{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a540231",
   "metadata": {},
   "source": [
    "# Collection: copublications internationales (UE et hors UE)\n",
    "* demande interne INRIA (27/07/2025)\n",
    "* Réalisation du script (adaptation d'un ancien script) : Kumar Guha (Data DCIS/Inria)\n",
    "* Date 27/02/2025, modifié le 29/08/2025. Denière version : 15/09/2025.\n",
    "\n",
    "## Choix\n",
    "* On ne retient que la première affiliation de chaque auteur (pas les niveaux supérieurs : exemple : Boston University School of Medicine et pas Boston University).\n",
    "* Si un auteur rattaché à une structure française est aussi rattaché à une structure étrangère, on ne retient pas cet auteur pour compter une copublication internationale.\n",
    "* Si un auteur de la structure Inria recherchée est aussi affilié à une autre strucutre étrangère, celle-ci n'est pas mentionnée.\n",
    "\n",
    "\n",
    "## Étapes\n",
    "* Extraire les publications des équipes concernées.\n",
    "* identifier les publications dont les auteurs sont affiliés à un organisme étranger (hors France et DOM TOM)\n",
    "* On crée des listes d'identifiants uniques pour les affiliations FR, Union Européenne et hors UE.\n",
    "    *  on exclut les organismes étrangers dont les auteurs sont aussi affiliés à une structure FR\n",
    "    *  on exclut les affiliations en double pour une même publication\n",
    "    *  nettoyage des données.\n",
    "* Génération d'un fichier Excel avec : chiffres, liste des publications, liste des organismes étrangers copubliants\n",
    "* Première identification de la ville d'après \n",
    "    * dictionnaire déjà constitué par les recherches précédentes\n",
    "    * nom de la ville entre crochets dans le nom de l'organisme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c08c50",
   "metadata": {},
   "source": [
    "## Extraction des publications de HAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd12968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "###############################################################\n",
    "## Extraction des publications de HAL\n",
    "##############################################\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from lxml import etree\n",
    "import gc \n",
    "import locale\n",
    "import re\n",
    "\n",
    "###############################################################################################\n",
    "##################### variables à modifier avant lancement du script ##########################\n",
    "###############################################################################################\n",
    "\n",
    "###########################################################\n",
    "# Définir la structure recherchée:\n",
    "###########################################################\n",
    "nom_collection = \"INRIA\" # il s'agit des publications des équipes Inria de tous les centres.\n",
    "\n",
    "# Identifiant de la structure \"de réference\" dont on analyse les publications (exemple Centre Inria de Rennes : 419153)\n",
    "#(à chercher dans Aurehal : https://aurehal.archives-ouvertes.fr/structure/index)\n",
    "i# Dictionnaire des structures\n",
    "structures = {\n",
    "    \"419153\": \"Rennes\",\n",
    "    \"104751\": \"Bordeaux\",\n",
    "    \"34586\": \"Sophia\",\n",
    "    \"2497\": \"Grenoble\",\n",
    "    \"1096051\": \"Lyon\",\n",
    "    \"129671\": \"Nancy\",\n",
    "    \"104752\": \"Lille\",\n",
    "    \"118511\": \"Saclay\",\n",
    "    \"454310\": \"Paris\",\n",
    "    \"1175218\": \"Paris(sorb)\",\n",
    "    \"1225635\": \"Saclay (ipp)\",\n",
    "    \"1225627\": \"Saclay (UPS)\"\n",
    "}\n",
    "\n",
    "# Structures à exclure\n",
    "# Galinette, Stack (id Aurehal :1088569,495900, 1088566, 525233 )\n",
    "equipes_a_exclure = []\n",
    "\n",
    "##########################################\n",
    "# Définir la période recherchée\n",
    "###########################################\n",
    "annee_debut = 2018\n",
    "annee_fin = 2025 # indiquer la même année si la recherche porte sur une seule année\n",
    "pas = 3\n",
    "\n",
    "def extraire_publications(id_aurehal_de_la_structure, nom_de_la_structure):\n",
    "    for start_year in range(annee_debut, annee_fin + 1, pas):\n",
    "        end_year = min(start_year + pas - 1, annee_fin)\n",
    "        periode = f\"[{start_year} TO {end_year}]\"\n",
    "        print(f\"▶️ {nom_de_la_structure} ({id_aurehal_de_la_structure}) : Traitement de la période : {periode}\")\n",
    "        \n",
    "        # Initialisation de toutes tes variables, comme dans ton script source\n",
    "        params = {\n",
    "            \"q\": f\"publicationDateY_i:{periode}\",\n",
    "            \"fq\": f\"structId_i:{id_aurehal_de_la_structure}\",\n",
    "            \"wt\": \"xml-tei\",\n",
    "            \"rows\": 1,\n",
    "            \"sort\": \"docid asc\"\n",
    "        }\n",
    "    #####################################################################\n",
    "    ##################### script ########################################\n",
    "    #####################################################################\n",
    "    # Obtenir la date actuelle\n",
    "    date_extraction_current = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    ## Spécifier le répertoire de log\n",
    "    log_directory = '../log/'\n",
    "    ## Créer le répertoire s'il n'existe pas\n",
    "    os.makedirs(log_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Configuration du logger\n",
    "    log_file = date_extraction_current + '__international_publications_log.txt'\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "    # Configurer la localisation en français\n",
    "    locale.setlocale(locale.LC_TIME, \"French_France.1252\")\n",
    "\n",
    "    # La période est définie par les années saisies dans les variables au-dessus du script\n",
    "\n",
    "    # periode = \"[\" + annee_debut + \" TO \" + annee_fin + \"]\"\n",
    "\n",
    "    # variables cumulatives\n",
    "\n",
    "    all_dataex = {}\n",
    "    all_datafr = {}\n",
    "    all_datapubli = []\n",
    "    params = {}\n",
    "    pas = 3\n",
    "\n",
    "    for start_year in range(annee_debut, annee_fin + 1, pas):\n",
    "        end_year = min(start_year + pas - 1, annee_fin)\n",
    "        periode = f\"[{start_year} TO {end_year}]\"\n",
    "        \n",
    "        print(f\"▶️ Traitement de la période : {periode}\")\n",
    "        \n",
    "        params[\"q\"] = f\"publicationDateY_i:{periode}\"\n",
    "        \n",
    "        # Réinitialise tes variables internes ici si besoin :\n",
    "        cursor_mark = \"*\"\n",
    "        previous_cursor_mark = None\n",
    "        compteur = 0\n",
    "        partenaire = 0\n",
    "        dataex = []\n",
    "        datafr = []\n",
    "        datapubli = []\n",
    "        unique_org_ex = {}\n",
    "        unique_org_fr = {}\n",
    "\n",
    "\n",
    "        # Fonction permettant de réessayer s'il n'y a pas de réponse\n",
    "        def fetch_with_retry(url, params=None, max_retries=3, delay=2):\n",
    "            \"\"\"\n",
    "            Effectue une requête GET avec plusieurs tentatives en cas d'échec.\n",
    "            \n",
    "            Args:\n",
    "                url (str): L'URL de la requête.\n",
    "                params (dict, optional): Paramètres de requête.\n",
    "                max_retries (int): Nombre maximal de tentatives.\n",
    "                delay (int): Temps d'attente entre chaque tentative (en secondes).\n",
    "\n",
    "            Returns:\n",
    "                Response object si la requête réussit, sinon None.\n",
    "            \"\"\"\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = requests.get(url, params=params, timeout=10)  # Timeout pour éviter les blocages\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        return response  # Succès\n",
    "                    \n",
    "                    print(f\"⚠️ Tentative {attempt + 1} échouée ({response.status_code}). Nouvelle tentative...\")\n",
    "\n",
    "                except requests.RequestException as e:\n",
    "                    print(f\"⏳ Erreur réseau ({e}), tentative {attempt + 1}...\")\n",
    "\n",
    "\n",
    "        #### Processus de récupération de la liste des notices présentes dans HAL pour la période spécifiée\n",
    "        # URL de base de l'API\n",
    "        base_url = f\"https://api.archives-ouvertes.fr/search/{nom_collection}?\"\n",
    "\n",
    "        # Paramètres de la requête : les résultats sont traités un par un en xml-tei\n",
    "        params = {\n",
    "            \"q\": f\"publicationDateY_i:{periode}\",\n",
    "            \"fq\": f\"structId_i:{id_aurehal_de_la_structure}\",\n",
    "            \"wt\": \"xml-tei\",\n",
    "            \"rows\": 1,\n",
    "            \"sort\": \"docid asc\"\n",
    "        }\n",
    "\n",
    "        # https://api.archives-ouvertes.fr/search/INRIA2?q=publicationDateY_i:[2019%20TO%202024]&fq=structId_i:(413916%20OR%20526070%20OR%20526181%20OR%20521735%20OR%20521714)&wt=xml-tei&rows=100&sort=docid%20asc\n",
    "\n",
    "        # Initialisation du cursorMark (qui permet de réitérer la requête jusqu'à la fin des réponses de l'API)\n",
    "        cursor_mark = \"*\"\n",
    "        previous_cursor_mark = None\n",
    "\n",
    "        # Définition des variables\n",
    "        compteur = 0\n",
    "        compte_publisUps = 0\n",
    "        partenaire = 0\n",
    "        dataex = []\n",
    "        datafr = []\n",
    "        datapubli = []\n",
    "        unique_org_ex = {}\n",
    "        unique_org_fr = {}\n",
    "        # Exclure les DOM-TOM français\n",
    "        France_et_dom_tom_codes = ['FR','GP', 'RE', 'MQ', 'GF', 'YT', 'PM', 'WF', 'TF', 'NC', 'PF']\n",
    "\n",
    "\n",
    "        namespaces = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "\n",
    "\n",
    "        #######################################\n",
    "        # La requête est lancée en boucle et obtient un résultat (une notice) à chaque fois\n",
    "        # chaque résultat est traité dans la boucle \"while\"\n",
    "        ########################################\n",
    "        while cursor_mark != previous_cursor_mark:\n",
    "            # Mise à jour du cursorMark\n",
    "            params[\"cursorMark\"] = cursor_mark\n",
    "            #print(f\"CursorMark: {cursor_mark}\")\n",
    "            compteur += 1\n",
    "            if compteur % 5000 == 0 or compteur == 1:\n",
    "                print(compteur)\n",
    "                if compteur % 5000 == 0:\n",
    "                    # Convertir les données collectées pour les organismes étrangers\n",
    "                    dataex = list(unique_org_ex.values())\n",
    "                    df_ex = pd.DataFrame(dataex)\n",
    "                    # Convertir les données collectées pour les organismes français\n",
    "                    datafr = list(unique_org_fr.values())\n",
    "                    df_fr = pd.DataFrame(datafr)\n",
    "\n",
    "                    # Liste des publications/logiciels de HAL\n",
    "                    df_publis = pd.DataFrame(datapubli)\n",
    "                    # df_ex.to_excel(f\"df_ex_{compteur}.xlsx\", index=False)\n",
    "                    # df_fr.to_excel(f\"df_fr_{compteur}.xlsx\", index=False)\n",
    "                    # df_publis.to_excel(f\"df_publis_{compteur}.xlsx\", index=False)\n",
    "                time.sleep(2)  # Pause de 2 secondes entre les requêtes\n",
    "        \n",
    "            # Limite pour tests\n",
    "            # if compteur > 15:\n",
    "            #     break\n",
    "\n",
    "            response = fetch_with_retry(base_url, params)\n",
    "            if response:\n",
    "                try:\n",
    "                    tree = etree.fromstring(response.content)\n",
    "                except etree.XMLSyntaxError:\n",
    "                    print(\"Erreur de syntaxe XML. Réponse non analysée.\")\n",
    "                    continue\n",
    "\n",
    "                # Récupération de la valeur de next dans l'attribut de la première balise TEI\n",
    "                next_cursor_mark = tree.attrib.get(\"next\")\n",
    "                # print(next_cursor_mark)\n",
    "                \n",
    "                # indication du nombre de notices répondant à la requête\n",
    "                quantity_value = tree.find('.//tei:measure', namespaces=namespaces).attrib.get('quantity')\n",
    "                \n",
    "                if cursor_mark == \"*\":\n",
    "                    # seulement lors de la première boucle, on indique le nombre total de notices répondant à la requête\n",
    "                    print(f\"nbre résultats : {quantity_value}. Durée estimée pour 4000 notices : 20 mn\")\n",
    "\n",
    "                # identification de la notice dans le xml-tei pour trouver les métadonnées\n",
    "                biblfull_elements = tree.findall('.//tei:biblFull', namespaces=namespaces)\n",
    "\n",
    "                if biblfull_elements:\n",
    "                    biblfull = biblfull_elements[0]  # Get the first matching element\n",
    "                else:\n",
    "                    biblfull = None  # Handle the absence of the element\n",
    "                    if cursor_mark == next_cursor_mark:\n",
    "                        print(f\"ancien curseur : {cursor_mark} - nouveau curseur : {next_cursor_mark}\")\n",
    "                        print(\"pas de biblFull - Terminé\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Il y a eu un problème dans la réponse de HAL, veuillez relancer le script\")\n",
    "                        break\n",
    "\n",
    "                # Récupération des metadonnées\n",
    "                if biblfull is not None:\n",
    "                    #identifiant de la publication dans HAL\n",
    "                    halID = biblfull.xpath('.//tei:publicationStmt/tei:idno[@type=\"halId\"]/text()', namespaces=namespaces) or [\"pas de hal_ID\"]\n",
    "                    halID_value = halID[0] if halID else \"no HalID\"\n",
    "                    # print(halID_value)\n",
    "                    \n",
    "                    # Domaines = biblfull.xpath('.//tei:profileDesc/tei:textClass/tei:classCode[@scheme=\"halDomain\"]/text()', namespaces=namespaces)\n",
    "                    # Domaines_value = \";\".join(domaine.strip() for domaine in Domaines if domaine)\n",
    "\n",
    "\n",
    "                    # TRAITEMENT DES AFFILIATIONS contenues dans la notice\n",
    "                    orgs = tree.findall('.//tei:listOrg[@type=\"structures\"]/tei:org', namespaces=namespaces)\n",
    "\n",
    "                    for org in orgs:\n",
    "                        xml_id = org.xpath('@xml:id', namespaces=namespaces) # code de la structure\n",
    "                        lenom = org.xpath('.//tei:orgName/text()', namespaces=namespaces)\n",
    "                        lacronyme = org.xpath('.//tei:orgName[@type=\"acronym\"]/text()', namespaces=namespaces)\n",
    "                        lepays = org.xpath('.//tei:country/@key', namespaces=namespaces)\n",
    "                        ladresse = [addr.text for addr in org.xpath('.//tei:addrLine', namespaces=namespaces) if addr.text]\n",
    "                        ladresse_value = \" \".join(ladresse)\n",
    "                        lesrelations = org.xpath('.//tei:listRelation/tei:relation/@active', namespaces=namespaces) # codes des structures parentes\n",
    "\n",
    "                        # Supprimer '#struct-' de chaque élément de la liste\n",
    "                        lesrelations_cleaned = [relation.replace('#struct-', '') for relation in lesrelations]\n",
    "                        xml_id_cleaned = xml_id[0].lstrip('struct-') \n",
    "                        \n",
    "                        # si l'identifiant structure fait partie des identifiants à exclure on passe au suivant sans traiter.\n",
    "                        # if xml_id_cleaned in equipes_a_exclure:\n",
    "                        #     continue\n",
    "\n",
    "                        # Organismes copubliants non français\n",
    "                        if lepays and lepays[0] not in France_et_dom_tom_codes:\n",
    "\n",
    "                            # print (f\"{xml_id_cleaned} trouvé\")\n",
    "                            partenaire = 1 # à noter qu'il peut s'agir d'une structure mère étrangère qui ne va pas entrer en compte au final\n",
    "                            unique_org_ex[xml_id[0]] = {\n",
    "                                \"Pays_ex\": lepays,  # Le pays (on filtrera ensuite)\n",
    "                                \"OrganismeEx\": lenom[0],  # Les noms des institutions\n",
    "                                \"ID_aurehal\": xml_id_cleaned,  # L'attribut xml:id\n",
    "                                \"adresse\": ladresse_value,\n",
    "                                \"parents\": lesrelations_cleaned\n",
    "\n",
    "                            }\n",
    "                        # Organisme FR\n",
    "                        elif lepays and lepays[0] in France_et_dom_tom_codes:\n",
    "\n",
    "                            #print(lepays)\n",
    "                            unique_org_fr[xml_id[0]] = {\n",
    "                                \"Pays_fr\": lepays,  # Le pays\n",
    "                                \"Organisme_fr\": lenom[0],  # Les noms des institutions\n",
    "                                \"Acronyme_fr\": lacronyme[0] if lacronyme else 'na',\n",
    "                                \"ID_aurehal\": xml_id_cleaned,  # L'attribut xml:id\n",
    "                                \"adresse\": ladresse_value,\n",
    "                                \"parents\": lesrelations_cleaned\n",
    "\n",
    "                            }\n",
    "                    \n",
    "                    # Si on veut limiter les résultats aux publications avec des copubliants internationaux alors il faut décommenter la ligne suivante      \n",
    "                    if partenaire == 1: # si on a trouvé un pays hors FR\n",
    "                \n",
    "                    # et il faut décaler les lignes suivantes aussi\n",
    "                    # Sinon, on prend toutes les publications (par ex, si on veut calculer la proportion de copublications avec l'étranger par rapport au total)\n",
    "\n",
    "                        # Récupération de l'année de publication   \n",
    "                        \n",
    "                        date_value = biblfull.xpath('.//tei:sourceDesc/tei:biblStruct//tei:monogr/tei:imprint/tei:date[@type=\"datePub\"]/text()', namespaces=namespaces)\n",
    "                        date_produced = biblfull.xpath('.//tei:editionStmt/tei:edition/tei:date[@type=\"whenProduced\"]/text()', namespaces=namespaces)\n",
    "                        if date_value and date_value is not None:\n",
    "                            date_text = date_value[0]  # Récupérer la chaîne de date\n",
    "                            year_value = date_text[:4]  # Les 4 premiers caractères pour l'année\n",
    "                        else:\n",
    "                            year_value = date_produced[0][:4]\n",
    "\n",
    "                        keywords = biblfull.xpath('.//tei:profileDesc/tei:textClass/tei:keywords/tei:term', namespaces=namespaces)\n",
    "                        # Extraire les mots-clés et joindre avec \";\"\n",
    "                        keywords_str = \";\".join(\n",
    "                            \" \".join(term.text.split())  # supprime espaces multiples et trims\n",
    "                            for term in keywords\n",
    "                            if term.text\n",
    "                        )\n",
    "                        # Récupérer tous les <classCode> avec scheme=\"halDomain\"\n",
    "                        hal_domain_elems = biblfull.xpath(\n",
    "                            './/tei:profileDesc/tei:textClass/tei:classCode[@scheme=\"halDomain\"]',\n",
    "                            namespaces=namespaces\n",
    "                        )\n",
    "\n",
    "                        # Nettoyer et joindre avec \";\"\n",
    "                        if hal_domain_elems:\n",
    "                            hal_domain_str = \";\".join(\n",
    "                                elem.text.strip() for elem in hal_domain_elems if elem.text\n",
    "                            )\n",
    "                        else:\n",
    "                            hal_domain_str = \"\"\n",
    "                            \n",
    "                        # Récupérer <abstract> en priorité \"en\", sinon \"fr\", sinon chaîne vide\n",
    "                        def get_full_text(elem):\n",
    "                            return \"\".join(elem.itertext()).strip() if elem is not None else \"\"\n",
    "                        abstract_elem = biblfull.xpath(\n",
    "                            './/tei:profileDesc/tei:abstract[@xml:lang=\"en\"]',\n",
    "                            namespaces=namespaces\n",
    "                        )\n",
    "                        if not abstract_elem:  # fallback en \"fr\"\n",
    "                            abstract_elem = biblfull.xpath(\n",
    "                                './/tei:profileDesc/tei:abstract[@xml:lang=\"fr\"]',\n",
    "                                namespaces=namespaces\n",
    "                            )\n",
    "                        abstract_str = get_full_text(abstract_elem[0]) if abstract_elem else \"\"\n",
    "                        \n",
    "                        # titre_revue = titre_journal[0].text if titre_journal  else \"\"\n",
    "                        # # print(titre_revue)\n",
    "                        # conference_titles = biblfull.xpath('.//tei:sourceDesc/tei:biblStruct/tei:monogr/tei:meeting/tei:title', namespaces=namespaces)\n",
    "                        # titre_conf = conference_titles[0].text if conference_titles else \"\"\n",
    "                        # print(titre_conf)\n",
    "                \n",
    "                    \n",
    "                    # Identification des affiliations associées à chaque auteur\n",
    "                        for author in biblfull.xpath('.//tei:titleStmt/tei:author', namespaces=namespaces):\n",
    "                            forename = author.xpath('.//tei:persName/tei:forename/text()', namespaces=namespaces)  or [\"Unknown\"]\n",
    "                            surname = author.xpath('.//tei:persName/tei:surname/text()', namespaces=namespaces)  or [\"Unknown\"]\n",
    "                                            \n",
    "                            authorLastFirstnames = (f\"{surname[0]}, {forename[0]}\")\n",
    "\n",
    "                            affiliations = author.xpath('.//tei:affiliation/@ref', namespaces=namespaces)\n",
    "\n",
    "                            for affiliation in affiliations:\n",
    "                                affiliation = affiliation.lstrip('#struct-')\n",
    "\n",
    "                                # si l'identifiant structure fait partie des identifiants à exclure on passe au suivant sans traiter.\n",
    "                                # if affiliation in equipes_a_exclure:\n",
    "                                #     continue\n",
    "\n",
    "                                datapubli.append ({\n",
    "                                    \"halID\" : halID_value,\n",
    "                                    \"Auteur\" : authorLastFirstnames,\n",
    "                                    \"affiliation\" : affiliation,\n",
    "                                    \"Centre\" : nom_struct if nom_struct else None\n",
    "                                    \"Annee\" : year_value,\n",
    "                                    \"MotsCles\": keywords_str,\n",
    "                                    \"Domaine(s)\":hal_domain_str,\n",
    "                                    \"Resume\":abstract_str,\n",
    "                                })\n",
    "                        partenaire = 0\n",
    "\n",
    "                    #print(f\"{halID_value} - {authorLastFirstnames} - {affiliation}\")\n",
    "                        \n",
    "                    # En cas de récupération intensive de données, forcer la libération de la mémoire\n",
    "                    # gc.collect()\n",
    "\n",
    "                    # Mise à jour du cursorMark pour la prochaine itération\n",
    "                    previous_cursor_mark = cursor_mark\n",
    "                    cursor_mark = next_cursor_mark\n",
    "                    # Pause pour éviter de surcharger l'API\n",
    "                    # time.sleep(0.1)\n",
    "\n",
    "                    if not next_cursor_mark:\n",
    "                        print(compteur)\n",
    "                        break\n",
    "\n",
    "    # Ajoute les résultats cumulés\n",
    "    all_dataex.update(unique_org_ex)\n",
    "    all_datafr.update(unique_org_fr)\n",
    "    all_datapubli.extend(datapubli)\n",
    "\n",
    "for id_aurehal, nom_struct in structures.items():\n",
    "    extraire_publications(id_aurehal, nom_struct)\n",
    "\n",
    "print(\"Terminé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Rennes (419153) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2545. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Rennes (419153) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2439. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Rennes (419153) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1633. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Problème dans la réponse API, veuillez relancer.\n",
      "▶️ Bordeaux (104751) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1489. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Bordeaux (104751) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1593. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Bordeaux (104751) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1023. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Sophia (34586) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2657. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Sophia (34586) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2919. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Sophia (34586) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1721. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Grenoble (2497) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2483. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Grenoble (2497) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1869. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Grenoble (2497) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 977. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Lyon (1096051) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 137. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Lyon (1096051) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 753. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Lyon (1096051) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 800. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Nancy (129671) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1646. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Nancy (129671) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1513. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Nancy (129671) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 871. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Lille (104752) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1321. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Lille (104752) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1362. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Lille (104752) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 786. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (118511) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2262. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (118511) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2611. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (118511) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1749. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Paris (454310) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2608. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Paris (454310) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 2651. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Paris (454310) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1694. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Paris(sorb) (1175218) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 423. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Paris(sorb) (1175218) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 739. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Paris(sorb) (1175218) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 423. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (ipp) (1225635) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 579. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (ipp) (1225635) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 808. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (ipp) (1225635) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 613. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (UPS) (1225627) : Traitement de la période : [2018 TO 2020]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 314. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (UPS) (1225627) : Traitement de la période : [2021 TO 2023]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 1374. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "▶️ Saclay (UPS) (1225627) : Traitement de la période : [2024 TO 2025]\n",
      "Nombre de notices traitées : 1\n",
      "Nombre total de résultats pour cette période : 909. Estimation durée: ~20 mn pour 4000 notices.\n",
      "Aucune notice trouvée - fin de la récupération.\n",
      "Extraction terminée. Résultats cumulés dans all_dataex, all_datafr, all_datapubli\n"
     ]
    }
   ],
   "source": [
    "######## NOUVELLE VERSION ################\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from lxml import etree\n",
    "import locale\n",
    "\n",
    "# Dictionnaire des structures à interroger\n",
    "structures = {\n",
    "    \"419153\": \"Rennes\",\n",
    "    \"104751\": \"Bordeaux\",\n",
    "    \"34586\": \"Sophia\",\n",
    "    \"2497\": \"Grenoble\",\n",
    "    \"1096051\": \"Lyon\",\n",
    "    \"129671\": \"Nancy\",\n",
    "    \"104752\": \"Lille\",\n",
    "    \"118511\": \"Saclay\",\n",
    "    \"454310\": \"Paris\",\n",
    "    \"1175218\": \"Paris(sorb)\",\n",
    "    \"1225635\": \"Saclay (ipp)\",\n",
    "    \"1225627\": \"Saclay (UPS)\"\n",
    "}\n",
    "\n",
    "nom_collection = \"INRIA\"\n",
    "annee_debut = 2018\n",
    "annee_fin = 2025\n",
    "pas = 3\n",
    "\n",
    "# Codes pays France et DOM-TOM pour filtrage\n",
    "France_et_dom_tom_codes = ['FR','GP', 'RE', 'MQ', 'GF', 'YT', 'PM', 'WF', 'TF', 'NC', 'PF']\n",
    "\n",
    "# Initialisation globale des cumuls des données\n",
    "all_dataex = {}\n",
    "all_datafr = {}\n",
    "all_datapubli = []\n",
    "\n",
    "# Configuration du logger (répertoire et fichier)\n",
    "date_extraction_current = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "log_directory = '../log/'\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "log_file = os.path.join(log_directory, date_extraction_current + '__international_publications_log.txt')\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Configuration locale française\n",
    "locale.setlocale(locale.LC_TIME, \"French_France.1252\")\n",
    "\n",
    "def fetch_with_retry(url, params=None, max_retries=3, delay=2):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "            print(f\"⚠️ Tentative {attempt + 1} échouée ({response.status_code}). Nouvelle tentative...\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"⏳ Erreur réseau ({e}), tentative {attempt + 1}...\")\n",
    "        time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "def extraire_publications(id_aurehal, nom_struct):\n",
    "    base_url = f\"https://api.archives-ouvertes.fr/search/{nom_collection}?\"\n",
    "    for start_year in range(annee_debut, annee_fin + 1, pas):\n",
    "        end_year = min(start_year + pas - 1, annee_fin)\n",
    "        periode = f\"[{start_year} TO {end_year}]\"\n",
    "        print(f\"▶️ {nom_struct} ({id_aurehal}) : Traitement de la période : {periode}\")\n",
    "\n",
    "        params = {\n",
    "            \"q\": f\"publicationDateY_i:{periode}\",\n",
    "            \"fq\": f\"structId_i:{id_aurehal}\",\n",
    "            \"wt\": \"xml-tei\",\n",
    "            \"rows\": 1,\n",
    "            \"sort\": \"docid asc\"\n",
    "        }\n",
    "\n",
    "        cursor_mark = \"*\"\n",
    "        previous_cursor_mark = None\n",
    "        compteur = 0\n",
    "        partenaire = 0\n",
    "\n",
    "        unique_org_ex = {}\n",
    "        unique_org_fr = {}\n",
    "        datapubli = []\n",
    "\n",
    "        namespaces = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "\n",
    "        while cursor_mark != previous_cursor_mark:\n",
    "            params[\"cursorMark\"] = cursor_mark\n",
    "            compteur += 1\n",
    "            if compteur % 5000 == 0 or compteur == 1:\n",
    "                print(f\"Nombre de notices traitées : {compteur}\")\n",
    "                # Optionnel: exporter ou sauvegarder les données partiellement ici\n",
    "\n",
    "            response = fetch_with_retry(base_url, params)\n",
    "            if not response:\n",
    "                print(\"Échec de la récupération des données après plusieurs tentatives.\")\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                tree = etree.fromstring(response.content)\n",
    "            except etree.XMLSyntaxError:\n",
    "                print(\"Erreur de syntaxe XML. Réponse non analysée.\")\n",
    "                continue\n",
    "\n",
    "            next_cursor_mark = tree.attrib.get(\"next\")\n",
    "            quantity_value = tree.find('.//tei:measure', namespaces=namespaces).attrib.get('quantity') if tree.find('.//tei:measure', namespaces=namespaces) is not None else \"0\"\n",
    "\n",
    "            if cursor_mark == \"*\":\n",
    "                print(f\"Nombre total de résultats pour cette période : {quantity_value}. Estimation durée: ~20 mn pour 4000 notices.\")\n",
    "\n",
    "            biblfull_elements = tree.findall('.//tei:biblFull', namespaces=namespaces)\n",
    "            if not biblfull_elements:\n",
    "                if cursor_mark == next_cursor_mark:\n",
    "                    print(\"Aucune notice trouvée - fin de la récupération.\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Problème dans la réponse API, veuillez relancer.\")\n",
    "                    break\n",
    "            biblfull = biblfull_elements[0]\n",
    "\n",
    "            # Récupération id HAL\n",
    "            halID = biblfull.xpath('.//tei:publicationStmt/tei:idno[@type=\"halId\"]/text()', namespaces=namespaces) or [\"pas de hal_ID\"]\n",
    "            halID_value = halID[0]\n",
    "\n",
    "            # Traitement des affiliations\n",
    "            orgs = tree.findall('.//tei:listOrg[@type=\"structures\"]/tei:org', namespaces=namespaces)\n",
    "            for org in orgs:\n",
    "                xml_id = org.xpath('@xml:id', namespaces=namespaces)\n",
    "                lenom = org.xpath('.//tei:orgName/text()', namespaces=namespaces)\n",
    "                lacronyme = org.xpath('.//tei:orgName[@type=\"acronym\"]/text()', namespaces=namespaces)\n",
    "                lepays = org.xpath('.//tei:country/@key', namespaces=namespaces)\n",
    "                ladresse = [addr.text for addr in org.xpath('.//tei:addrLine', namespaces=namespaces) if addr.text]\n",
    "                ladresse_value = \" \".join(ladresse)\n",
    "                lesrelations = org.xpath('.//tei:listRelation/tei:relation/@active', namespaces=namespaces)\n",
    "\n",
    "                lesrelations_cleaned = [relation.replace('#struct-', '') for relation in lesrelations]\n",
    "                xml_id_cleaned = xml_id[0].lstrip('struct-') \n",
    "\n",
    "                # Exclusion non appliquée (décommenter si besoin)\n",
    "                # if xml_id_cleaned in equipes_a_exclure:\n",
    "                #     continue\n",
    "\n",
    "                if lepays and lepays[0] not in France_et_dom_tom_codes:\n",
    "                    partenaire = 1\n",
    "                    unique_org_ex[xml_id[0]] = {\n",
    "                        \"Pays_ex\": lepays,\n",
    "                        \"OrganismeEx\": lenom[0] if lenom else '',\n",
    "                        \"ID_aurehal\": xml_id_cleaned,\n",
    "                        \"adresse\": ladresse_value,\n",
    "                        \"parents\": lesrelations_cleaned\n",
    "                    }\n",
    "                elif lepays and lepays[0] in France_et_dom_tom_codes:\n",
    "                    unique_org_fr[xml_id[0]] = {\n",
    "                        \"Pays_fr\": lepays,\n",
    "                        \"Organisme_fr\": lenom[0] if lenom else '',\n",
    "                        \"Acronyme_fr\": lacronyme[0] if lacronyme else 'na',\n",
    "                        \"ID_aurehal\": xml_id_cleaned,\n",
    "                        \"adresse\": ladresse_value,\n",
    "                        \"parents\": lesrelations_cleaned\n",
    "                    }\n",
    "\n",
    "            # Filtrer selon partenaire = 1 seulement, sinon prendre toutes les publications\n",
    "            if partenaire == 1: \n",
    "\n",
    "                date_value = biblfull.xpath('.//tei:sourceDesc/tei:biblStruct//tei:monogr/tei:imprint/tei:date[@type=\"datePub\"]/text()', namespaces=namespaces)\n",
    "                date_produced = biblfull.xpath('.//tei:editionStmt/tei:edition/tei:date[@type=\"whenProduced\"]/text()', namespaces=namespaces)\n",
    "                if date_value and date_value[0]:\n",
    "                    year_value = date_value[0][:4]\n",
    "                elif date_produced and date_produced[0]:\n",
    "                    year_value = date_produced[0][:4]\n",
    "                else:\n",
    "                    year_value = \"\"\n",
    "\n",
    "                keywords = biblfull.xpath('.//tei:profileDesc/tei:textClass/tei:keywords/tei:term', namespaces=namespaces)\n",
    "                keywords_str = \";\".join(\n",
    "                    \" \".join(term.text.split())\n",
    "                    for term in keywords if term.text\n",
    "                )\n",
    "\n",
    "                hal_domain_elems = biblfull.xpath('.//tei:profileDesc/tei:textClass/tei:classCode[@scheme=\"halDomain\"]', namespaces=namespaces)\n",
    "                hal_domain_str = \";\".join(elem.text.strip() for elem in hal_domain_elems if elem.text) if hal_domain_elems else \"\"\n",
    "\n",
    "                def get_full_text(elem):\n",
    "                    return \"\".join(elem.itertext()).strip() if elem is not None else \"\"\n",
    "\n",
    "                abstract_elem = biblfull.xpath('.//tei:profileDesc/tei:abstract[@xml:lang=\"en\"]', namespaces=namespaces)\n",
    "                if not abstract_elem:\n",
    "                    abstract_elem = biblfull.xpath('.//tei:profileDesc/tei:abstract[@xml:lang=\"fr\"]', namespaces=namespaces)\n",
    "                abstract_str = get_full_text(abstract_elem[0]) if abstract_elem else \"\"\n",
    "\n",
    "                # Extraction auteurs et affiliations\n",
    "                for author in biblfull.xpath('.//tei:titleStmt/tei:author', namespaces=namespaces):\n",
    "                    forename = author.xpath('.//tei:persName/tei:forename/text()', namespaces=namespaces) or [\"Unknown\"]\n",
    "                    surname = author.xpath('.//tei:persName/tei:surname/text()', namespaces=namespaces) or [\"Unknown\"]\n",
    "                    authorLastFirstnames = f\"{surname[0]}, {forename[0]}\"\n",
    "\n",
    "                    affiliations = author.xpath('.//tei:affiliation/@ref', namespaces=namespaces)\n",
    "                    for affiliation in affiliations:\n",
    "                        affiliation = affiliation.lstrip('#struct-')\n",
    "                        # if affiliation in equipes_a_exclure:\n",
    "                        #     continue\n",
    "\n",
    "                        datapubli.append({\n",
    "                            \"halID\": halID_value,\n",
    "                            \"Auteur\": authorLastFirstnames,\n",
    "                            \"affiliation\": affiliation,\n",
    "                            \"Centre\": nom_struct,\n",
    "                            \"Annee\": year_value,\n",
    "                            \"MotsCles\": keywords_str,\n",
    "                            \"Domaine(s)\": hal_domain_str,\n",
    "                            \"Resume\": abstract_str,\n",
    "                        })\n",
    "                partenaire = 0\n",
    "\n",
    "            previous_cursor_mark = cursor_mark\n",
    "            cursor_mark = next_cursor_mark\n",
    "\n",
    "            if not next_cursor_mark:\n",
    "                print(f\"Fin des résultats pour {nom_struct} période {periode}, total notices traitées : {compteur}\")\n",
    "                break\n",
    "            time.sleep(0.1)  # Pause courte pour ne pas surcharger\n",
    "\n",
    "        all_dataex.update(unique_org_ex)\n",
    "        all_datafr.update(unique_org_fr)\n",
    "        all_datapubli.extend(datapubli)\n",
    "\n",
    "# Boucle principale sur chaque structure au dictionnaire\n",
    "for id_aurehal, nom_struct in structures.items():\n",
    "    extraire_publications(id_aurehal, nom_struct)\n",
    "\n",
    "print(\"Extraction terminée. Résultats cumulés dans all_dataex, all_datafr, all_datapubli\")\n",
    "\n",
    "#Temps de traitement : entre 4 et 5h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64bfad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframes créés\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Conversion en \"dataframes\" pour traitement des données et comptage\n",
    "######################################################################\n",
    "\n",
    "df_ex = pd.DataFrame(list(all_dataex.values()))\n",
    "df_fr = pd.DataFrame(list(all_datafr.values()))\n",
    "df_publis = pd.DataFrame(all_datapubli)\n",
    "\n",
    "# Sauvegarde pour contrôle et tests\n",
    "# df_ex.to_excel(\"df_ex_total.xlsx\", index=False)\n",
    "# df_fr.to_excel(\"df_fr_total.xlsx\", index=False)\n",
    "# df_publis.to_excel(\"df_publis_total.xlsx\", index=False)\n",
    "print(\"dataframes créés\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450234ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframes créés\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde pour contrôle et tests\n",
    "df_ex.to_excel(\"df_ex_total.xlsx\", index=False)\n",
    "df_fr.to_excel(\"df_fr_total.xlsx\", index=False)\n",
    "df_publis.to_excel(\"df_publis_total.xlsx\", index=False)\n",
    "print(\"dataframes créés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pour tests : df_publis=pd.read_excel(\"df_publis_total.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67dd20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Soffer, Avy</td>\n",
       "      <td>452560</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Zhao, Xiaofei</td>\n",
       "      <td>525243</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Puy, Gilles</td>\n",
       "      <td>118587</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          halID         Auteur affiliation  Centre Annee  \\\n",
       "0  hal-01328959    Soffer, Avy      452560  Rennes  2018   \n",
       "1  hal-01328959  Zhao, Xiaofei      525243  Rennes  2018   \n",
       "2  hal-01229578    Puy, Gilles      118587  Rennes  2018   \n",
       "\n",
       "                                            MotsCles  \\\n",
       "0  vortex;radiation;modulation equations;numerica...   \n",
       "1  vortex;radiation;modulation equations;numerica...   \n",
       "2                                                      \n",
       "\n",
       "                                          Domaine(s)  \\\n",
       "0   Physics [physics]/Mathematical Physics [math-ph]   \n",
       "1   Physics [physics]/Mathematical Physics [math-ph]   \n",
       "2  Engineering Sciences [physics]/Signal and Imag...   \n",
       "\n",
       "                                              Resume  \n",
       "0  We apply the modulation theory to study the vo...  \n",
       "1  We apply the modulation theory to study the vo...  \n",
       "2  We study the problem of sampling k-bandlimited...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_publis.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5a75aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes UE et non UE créés\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\458932396.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_UE.rename(columns={\"OrganismeEx\" : \"Organisme_UE\"}, inplace=True)\n",
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\458932396.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nonUE.rename(columns={\"OrganismeEx\" : \"Organisme_Hors_UE\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################################\n",
    "# FILTRE UE / hors UE pour df_ex\n",
    "####################################\n",
    "df_nonUE = \"\"\n",
    "df_UE = \"\"\n",
    "pays_UE = [\n",
    "    \"AT\", \"BE\", \"BG\", \"HR\", \"CY\", \"CZ\", \"DK\", \"EE\", \"FI\", \"FR\",\n",
    "    \"DE\", \"GR\", \"HU\", \"IE\", \"IT\", \"LV\", \"LT\", \"LU\", \"MT\", \"NL\",\n",
    "    \"PL\", \"PT\", \"RO\", \"SK\", \"SI\", \"ES\", \"SE\"\n",
    "]\n",
    "\n",
    "# On va créer 2 dataframes en fonction du pays de la structure (UE ou hors UE)\n",
    "#\n",
    "\n",
    "# Fonction pour vérifier si une valeur de la liste est dans la colonne `identifiant` ou `parents`\n",
    "def filter_rows_EU(row):\n",
    "    # Vérifie si une des valeurs de la liste se trouve dans `country` ou dans les valeurs de `parents`\n",
    "    return any(country in pays_UE for country in row[\"Pays_ex\"])\n",
    "\n",
    "def filter_rows_ex(row):\n",
    "    # Vérifie si une des valeurs de la liste ne se trouve pas dans `country` ou dans les valeurs de `parents`\n",
    "    return any(country not in pays_UE for country in row[\"Pays_ex\"])\n",
    "\n",
    "\n",
    "# Filtrer les lignes du DataFrame pour garder celles des structures qui nous intéressent\n",
    "df_UE = df_ex[df_ex.apply(filter_rows_EU, axis=1)]\n",
    "df_UE.rename(columns={\"OrganismeEx\" : \"Organisme_UE\"}, inplace=True)\n",
    "\n",
    "\n",
    "df_nonUE = df_ex[df_ex.apply(filter_rows_ex, axis=1)]\n",
    "df_nonUE.rename(columns={\"OrganismeEx\" : \"Organisme_Hors_UE\"}, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Dataframes UE et non UE créés\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a09ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exemple : FR → France\n",
      "   Pays_ex                      Organisme_UE ID_aurehal  \\\n",
      "5  Germany  Institut für Mathematik [Berlin]       4560   \n",
      "\n",
      "                                            adresse  parents TypePays  \n",
      "5  Sekr. MA 4-1 Straße des 17.Juni 136 10623 Berlin  [86624]       EU  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\2021481470.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_UE[\"Pays_ex\"] = df_UE[\"Pays_ex\"].apply(lambda x: country_mapping.get(x[0]) if isinstance(x, list) and x else x)\n",
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\2021481470.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_UE['TypePays'] = \"EU\"\n",
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\2021481470.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nonUE[\"Pays_ex\"] = df_nonUE[\"Pays_ex\"].apply(lambda x: country_mapping.get(x[0]) if isinstance(x, list) and x else x)\n",
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\2021481470.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nonUE['TypePays'] = \"EX\"\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# Interprétation des codes Pays en noms en toutes lettres \n",
    "###########################################################\n",
    "\n",
    "# Récupérer les données de l'API\n",
    "# url = \"https://restcountries.com/v3.1/all\"\n",
    "# response = requests.get(url)\n",
    "# countries_data = response.json()\n",
    "import requests\n",
    "\n",
    "def get_country_mapping():\n",
    "    url = \"https://restcountries.com/v3.1/all\"\n",
    "    params = {\"fields\": \"cca2,name\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            countries_data = response.json()\n",
    "            if isinstance(countries_data, list):\n",
    "                return {\n",
    "                    country.get(\"cca2\"): country.get(\"name\", {}).get(\"common\")\n",
    "                    for country in countries_data\n",
    "                    if country.get(\"cca2\") and \"name\" in country and \"common\" in country[\"name\"]\n",
    "                }\n",
    "            else:\n",
    "                print(\"⚠️ Format inattendu :\", type(countries_data))\n",
    "                return {}\n",
    "        else:\n",
    "            print(f\"⚠️ Erreur API ({response.status_code}): {response.json().get('message')}\")\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(\"❌ Erreur lors de la récupération des données pays :\", e)\n",
    "        return {}\n",
    "\n",
    "# Utilisation\n",
    "country_mapping = get_country_mapping()\n",
    "print(\"✅ Exemple : FR →\", country_mapping.get(\"FR\"))  # Affiche 'France'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_UE[\"Pays_ex\"] = df_UE[\"Pays_ex\"].apply(lambda x: country_mapping.get(x[0]) if isinstance(x, list) and x else x)\n",
    "df_UE['TypePays'] = \"EU\"\n",
    "\n",
    "df_nonUE[\"Pays_ex\"] = df_nonUE[\"Pays_ex\"].apply(lambda x: country_mapping.get(x[0]) if isinstance(x, list) and x else x)\n",
    "df_nonUE['TypePays'] = \"EX\"\n",
    "\n",
    "df_fr[\"Pays_fr\"] = df_fr[\"Pays_fr\"].apply(lambda x: country_mapping.get(x[0]) if isinstance(x, list) and x else x)\n",
    "df_fr['TypePays'] = \"FR\"\n",
    "\n",
    "\n",
    "# Afficher un aperçu du DataFrame modifié\n",
    "print(df_UE.head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212e9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          halID                 Auteur affiliation acronyme\n",
      "0  hal-01328959            Soffer, Avy      452560      NaN\n",
      "1  hal-01328959          Zhao, Xiaofei      525243   MINGUS\n",
      "2  hal-01229578            Puy, Gilles      118587      NaN\n",
      "3  hal-01229578            Puy, Gilles      210613   PANAMA\n",
      "4  hal-01229578      Tremblay, Nicolas      210613   PANAMA\n",
      "5  hal-01229578      Tremblay, Nicolas       35484      NaN\n",
      "6  hal-01229578        Gribonval, Rémi      210613   PANAMA\n",
      "7  hal-01229578  Vandergheynst, Pierre       35484      NaN\n",
      "8  hal-01229578  Vandergheynst, Pierre      210613   PANAMA\n",
      "9  hal-01389489       Bailleul, Ismaël          75      NaN\n"
     ]
    }
   ],
   "source": [
    "########## \n",
    "# Ajouter l'acronyme des auteurs Inria dans la liste des publications\n",
    "###########\n",
    "\n",
    "# Charger ton fichier d'équipes Inria\n",
    "df_equipes = pd.read_excel(\"equipesInriadeAurehal.xlsx\")\n",
    "\n",
    "# Vérifie que les colonnes utiles existent\n",
    "assert \"docid\" in df_equipes.columns, \"Colonne 'docid' manquante dans le fichier Excel\"\n",
    "assert \"acronyme\" in df_equipes.columns, \"Colonne 'acronyme' manquante dans le fichier Excel\"\n",
    "\n",
    "# S'assurer que 'docid' et 'affiliation' sont bien de type str\n",
    "df_equipes[\"docid\"] = df_equipes[\"docid\"].astype(str)\n",
    "df_publis[\"affiliation\"] = df_publis[\"affiliation\"].astype(str)\n",
    "\n",
    "# Fusion des deux DataFrames : on ajoute l'acronyme en fonction de l'affiliation\n",
    "df_publis = df_publis.merge(df_equipes[[\"docid\", \"acronyme\"]], how=\"left\", left_on=\"affiliation\", right_on=\"docid\")\n",
    "\n",
    "# Optionnel : supprimer la colonne docid (redondante après le merge)\n",
    "df_publis.drop(columns=[\"docid\"], inplace=True)\n",
    "\n",
    "# Exemple d'affichage\n",
    "print(df_publis[[\"halID\", \"Auteur\", \"affiliation\", \"acronyme\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55be05e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27305</th>\n",
       "      <td>hal-00799242</td>\n",
       "      <td>Champagnat, Nicolas</td>\n",
       "      <td>206068</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2018</td>\n",
       "      <td>pathwise uniqueness;rough drift;rough diffusio...</td>\n",
       "      <td>Mathematics [math]/Probability [math.PR]</td>\n",
       "      <td>We study strong existence and pathwise uniquen...</td>\n",
       "      <td>TOSCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27306</th>\n",
       "      <td>hal-00799242</td>\n",
       "      <td>Champagnat, Nicolas</td>\n",
       "      <td>211251</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2018</td>\n",
       "      <td>pathwise uniqueness;rough drift;rough diffusio...</td>\n",
       "      <td>Mathematics [math]/Probability [math.PR]</td>\n",
       "      <td>We study strong existence and pathwise uniquen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27307</th>\n",
       "      <td>hal-00799242</td>\n",
       "      <td>Jabin, Pierre-Emmanuel</td>\n",
       "      <td>54156</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2018</td>\n",
       "      <td>pathwise uniqueness;rough drift;rough diffusio...</td>\n",
       "      <td>Mathematics [math]/Probability [math.PR]</td>\n",
       "      <td>We study strong existence and pathwise uniquen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              halID                  Auteur affiliation  Centre Annee  \\\n",
       "27305  hal-00799242     Champagnat, Nicolas      206068  Sophia  2018   \n",
       "27306  hal-00799242     Champagnat, Nicolas      211251  Sophia  2018   \n",
       "27307  hal-00799242  Jabin, Pierre-Emmanuel       54156  Sophia  2018   \n",
       "\n",
       "                                                MotsCles  \\\n",
       "27305  pathwise uniqueness;rough drift;rough diffusio...   \n",
       "27306  pathwise uniqueness;rough drift;rough diffusio...   \n",
       "27307  pathwise uniqueness;rough drift;rough diffusio...   \n",
       "\n",
       "                                     Domaine(s)  \\\n",
       "27305  Mathematics [math]/Probability [math.PR]   \n",
       "27306  Mathematics [math]/Probability [math.PR]   \n",
       "27307  Mathematics [math]/Probability [math.PR]   \n",
       "\n",
       "                                                  Resume acronyme  \n",
       "27305  We study strong existence and pathwise uniquen...    TOSCA  \n",
       "27306  We study strong existence and pathwise uniquen...      NaN  \n",
       "27307  We study strong existence and pathwise uniquen...      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  pour tests \n",
    "df_publis[df_publis[\"halID\"] == \"hal-00799242\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd4e5c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Soffer, Avy</td>\n",
       "      <td>452560</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Zhao, Xiaofei</td>\n",
       "      <td>525243</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "      <td>MINGUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Puy, Gilles</td>\n",
       "      <td>210613</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "      <td>PANAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Tremblay, Nicolas</td>\n",
       "      <td>210613</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "      <td>PANAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Gribonval, Rémi</td>\n",
       "      <td>210613</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "      <td>PANAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Vandergheynst, Pierre</td>\n",
       "      <td>210613</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "      <td>PANAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hal-01389489</td>\n",
       "      <td>Bailleul, Ismaël</td>\n",
       "      <td>75</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2019</td>\n",
       "      <td>Paracontrolled calculus;Quaslilinear parabolic...</td>\n",
       "      <td>Mathematics [math]/Analysis of PDEs [math.AP]</td>\n",
       "      <td>We provide in this work a local in time well-p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hal-01389489</td>\n",
       "      <td>Debussche, Arnaud</td>\n",
       "      <td>525243</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2019</td>\n",
       "      <td>Paracontrolled calculus;Quaslilinear parabolic...</td>\n",
       "      <td>Mathematics [math]/Analysis of PDEs [math.AP]</td>\n",
       "      <td>We provide in this work a local in time well-p...</td>\n",
       "      <td>MINGUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hal-01389489</td>\n",
       "      <td>Hofmanova, Martina</td>\n",
       "      <td>4560</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2019</td>\n",
       "      <td>Paracontrolled calculus;Quaslilinear parabolic...</td>\n",
       "      <td>Mathematics [math]/Analysis of PDEs [math.AP]</td>\n",
       "      <td>We provide in this work a local in time well-p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hal-01390478</td>\n",
       "      <td>Marschall, Tobias</td>\n",
       "      <td>92733</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Computer Science [cs]/Bioinformatics [q-bio.QM]</td>\n",
       "      <td>Many disciplines, from human genetics and onco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           halID                 Auteur affiliation  Centre Annee  \\\n",
       "0   hal-01328959            Soffer, Avy      452560  Rennes  2018   \n",
       "1   hal-01328959          Zhao, Xiaofei      525243  Rennes  2018   \n",
       "3   hal-01229578            Puy, Gilles      210613  Rennes  2018   \n",
       "4   hal-01229578      Tremblay, Nicolas      210613  Rennes  2018   \n",
       "6   hal-01229578        Gribonval, Rémi      210613  Rennes  2018   \n",
       "8   hal-01229578  Vandergheynst, Pierre      210613  Rennes  2018   \n",
       "9   hal-01389489       Bailleul, Ismaël          75  Rennes  2019   \n",
       "10  hal-01389489      Debussche, Arnaud      525243  Rennes  2019   \n",
       "11  hal-01389489     Hofmanova, Martina        4560  Rennes  2019   \n",
       "12  hal-01390478      Marschall, Tobias       92733  Rennes  2018   \n",
       "\n",
       "                                             MotsCles  \\\n",
       "0   vortex;radiation;modulation equations;numerica...   \n",
       "1   vortex;radiation;modulation equations;numerica...   \n",
       "3                                                       \n",
       "4                                                       \n",
       "6                                                       \n",
       "8                                                       \n",
       "9   Paracontrolled calculus;Quaslilinear parabolic...   \n",
       "10  Paracontrolled calculus;Quaslilinear parabolic...   \n",
       "11  Paracontrolled calculus;Quaslilinear parabolic...   \n",
       "12                                                      \n",
       "\n",
       "                                           Domaine(s)  \\\n",
       "0    Physics [physics]/Mathematical Physics [math-ph]   \n",
       "1    Physics [physics]/Mathematical Physics [math-ph]   \n",
       "3   Engineering Sciences [physics]/Signal and Imag...   \n",
       "4   Engineering Sciences [physics]/Signal and Imag...   \n",
       "6   Engineering Sciences [physics]/Signal and Imag...   \n",
       "8   Engineering Sciences [physics]/Signal and Imag...   \n",
       "9       Mathematics [math]/Analysis of PDEs [math.AP]   \n",
       "10      Mathematics [math]/Analysis of PDEs [math.AP]   \n",
       "11      Mathematics [math]/Analysis of PDEs [math.AP]   \n",
       "12    Computer Science [cs]/Bioinformatics [q-bio.QM]   \n",
       "\n",
       "                                               Resume acronyme  \n",
       "0   We apply the modulation theory to study the vo...      NaN  \n",
       "1   We apply the modulation theory to study the vo...   MINGUS  \n",
       "3   We study the problem of sampling k-bandlimited...   PANAMA  \n",
       "4   We study the problem of sampling k-bandlimited...   PANAMA  \n",
       "6   We study the problem of sampling k-bandlimited...   PANAMA  \n",
       "8   We study the problem of sampling k-bandlimited...   PANAMA  \n",
       "9   We provide in this work a local in time well-p...      NaN  \n",
       "10  We provide in this work a local in time well-p...   MINGUS  \n",
       "11  We provide in this work a local in time well-p...      NaN  \n",
       "12  Many disciplines, from human genetics and onco...      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nettoyage : Pour les auteurs Inria (auteurs ayant un acronyme), supprimer les autres affiliations\n",
    "# Marquer les cas où pour chaque (halID, Auteur), au moins un acronyme est non-null\n",
    "df=df_publis\n",
    "\n",
    "df[\"has_acronyme\"] = df.groupby([\"halID\", \"Auteur\"])[\"acronyme\"].transform(lambda x: x.notna().any())\n",
    "\n",
    "# Ne garder que :\n",
    "# - les lignes où acronyme est non-null\n",
    "# - ou les cas où aucune ligne pour ce (halID, Auteur) n'a d'acronyme\n",
    "df = df[(df[\"acronyme\"].notna()) | (~df[\"has_acronyme\"])]\n",
    "\n",
    "# Supprimer la colonne temporaire\n",
    "df = df.drop(columns=[\"has_acronyme\"])\n",
    "\n",
    "df_publis = df\n",
    "df_publis.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab58e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  affiliation Organisme_UE Pays_ex adresse_UE\n",
      "0      452560          NaN     NaN        NaN\n",
      "1      525243          NaN     NaN        NaN\n",
      "2      210613          NaN     NaN        NaN\n",
      "3      210613          NaN     NaN        NaN\n",
      "4      210613          NaN     NaN        NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\2947255803.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_UE[\"ID_aurehal\"] = df_UE[\"ID_aurehal\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Ajouter l'organisme et le pays UE des auteurs à la liste générale des publications\n",
    "\n",
    "# Vérifier que les colonnes existent\n",
    "assert \"ID_aurehal\" in df_UE.columns, \"Colonne 'ID_aurehal' manquante dans df_UE\"\n",
    "assert \"Organisme_UE\" in df_UE.columns, \"Colonne 'Organisme_UE' manquante dans df_UE\"\n",
    "assert \"Pays_ex\" in df_UE.columns, \"Colonne 'Pays_ex' manquante dans df_UE\"\n",
    "assert \"adresse\" in df_UE.columns, \"Colonne 'adresse' manquante dans df_UE\"\n",
    "\n",
    "# Harmoniser les types de colonnes pour le merge\n",
    "df_UE[\"ID_aurehal\"] = df_UE[\"ID_aurehal\"].astype(str)\n",
    "df_publis[\"affiliation\"] = df_publis[\"affiliation\"].astype(str)\n",
    "\n",
    "# Renommer les colonnes de df_nonUE pour éviter les collisions\n",
    "df_UE_renamed = df_UE.rename(columns={\n",
    "    \"adresse\": \"adresse_UE\",  # Pour éviter d’écraser la précédente\n",
    "})\n",
    "\n",
    "# Faire la jointure\n",
    "df_publis = df_publis.merge(\n",
    "    df_UE_renamed[[\"ID_aurehal\", \"Organisme_UE\", \"Pays_ex\",\"adresse_UE\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"affiliation\",\n",
    "    right_on=\"ID_aurehal\"\n",
    ")\n",
    "\n",
    "# Supprimer la colonne intermédiaire redondante\n",
    "df_publis.drop(columns=[\"ID_aurehal\"], inplace=True)\n",
    "\n",
    "# Vérification du résultat\n",
    "print(df_publis[[\"affiliation\", \"Organisme_UE\", \"Pays_ex\",\"adresse_UE\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonUE.head(1) #pour connaître le nom des colonnes afin de faire le traitement suivant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7fc718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  affiliation          Organisme_Hors_UE Pays_ex_horsUE  \\\n",
      "0      452560  Department of Mathematics  United States   \n",
      "1      525243                        NaN            NaN   \n",
      "2      210613                        NaN            NaN   \n",
      "3      210613                        NaN            NaN   \n",
      "4      210613                        NaN            NaN   \n",
      "\n",
      "                                     adresse_hors_UE  \n",
      "0  Hill Center for the Mathematical Sciences110 F...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kguha\\AppData\\Local\\Temp\\ipykernel_5116\\3645708706.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nonUE[\"ID_aurehal\"] = df_nonUE[\"ID_aurehal\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Ajouter l'organisme et le pays Hors UE des auteurs\n",
    "\n",
    "# Vérifier que les colonnes existent\n",
    "assert \"ID_aurehal\" in df_nonUE.columns, \"Colonne 'ID_aurehal' manquante dans df_nonUE\"\n",
    "assert \"Organisme_Hors_UE\" in df_nonUE.columns, \"Colonne 'Organisme_Hors_UE' manquante dans df_nonUE\"\n",
    "assert \"Pays_ex\" in df_nonUE.columns, \"Colonne 'Pays_ex' manquante dans df_nonUE\"\n",
    "assert \"adresse\" in df_nonUE.columns, \"Colonne 'adresse' manquante dans df_nonUE\"\n",
    "\n",
    "# Harmoniser les types de colonnes pour le merge\n",
    "df_nonUE[\"ID_aurehal\"] = df_nonUE[\"ID_aurehal\"].astype(str)\n",
    "df_publis[\"affiliation\"] = df_publis[\"affiliation\"].astype(str)\n",
    "\n",
    "# Renommer les colonnes de df_nonUE pour éviter les collisions\n",
    "df_nonUE_renamed = df_nonUE.rename(columns={\n",
    "    \"Pays_ex\": \"Pays_ex_horsUE\",  # Pour éviter d’écraser la précédente\n",
    "    \"adresse\": \"adresse_hors_UE\", \n",
    "})\n",
    "\n",
    "# Faire la jointure\n",
    "df_publis = df_publis.merge(\n",
    "    df_nonUE_renamed[[\"ID_aurehal\", \"Organisme_Hors_UE\", \"Pays_ex_horsUE\",\"adresse_hors_UE\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"affiliation\",\n",
    "    right_on=\"ID_aurehal\"\n",
    ")\n",
    "\n",
    "# Supprimer la colonne intermédiaire redondante\n",
    "df_publis.drop(columns=[\"ID_aurehal\"], inplace=True)\n",
    "\n",
    "# Vérification du résultat\n",
    "print(df_publis[[\"affiliation\", \"Organisme_Hors_UE\", \"Pays_ex_horsUE\",\"adresse_hors_UE\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51d4b603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "      <th>Organisme_UE</th>\n",
       "      <th>Pays_ex</th>\n",
       "      <th>adresse_UE</th>\n",
       "      <th>Organisme_Hors_UE</th>\n",
       "      <th>Pays_ex_horsUE</th>\n",
       "      <th>adresse_hors_UE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24088</th>\n",
       "      <td>hal-00799242</td>\n",
       "      <td>Champagnat, Nicolas</td>\n",
       "      <td>206068</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2018</td>\n",
       "      <td>pathwise uniqueness;rough drift;rough diffusio...</td>\n",
       "      <td>Mathematics [math]/Probability [math.PR]</td>\n",
       "      <td>We study strong existence and pathwise uniquen...</td>\n",
       "      <td>TOSCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24089</th>\n",
       "      <td>hal-00799242</td>\n",
       "      <td>Jabin, Pierre-Emmanuel</td>\n",
       "      <td>54156</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2018</td>\n",
       "      <td>pathwise uniqueness;rough drift;rough diffusio...</td>\n",
       "      <td>Mathematics [math]/Probability [math.PR]</td>\n",
       "      <td>We study strong existence and pathwise uniquen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Mathematics [College Park]</td>\n",
       "      <td>United States</td>\n",
       "      <td>4176 Campus Drive - William E. Kirwan Hall, Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              halID                  Auteur affiliation  Centre Annee  \\\n",
       "24088  hal-00799242     Champagnat, Nicolas      206068  Sophia  2018   \n",
       "24089  hal-00799242  Jabin, Pierre-Emmanuel       54156  Sophia  2018   \n",
       "\n",
       "                                                MotsCles  \\\n",
       "24088  pathwise uniqueness;rough drift;rough diffusio...   \n",
       "24089  pathwise uniqueness;rough drift;rough diffusio...   \n",
       "\n",
       "                                     Domaine(s)  \\\n",
       "24088  Mathematics [math]/Probability [math.PR]   \n",
       "24089  Mathematics [math]/Probability [math.PR]   \n",
       "\n",
       "                                                  Resume acronyme  \\\n",
       "24088  We study strong existence and pathwise uniquen...    TOSCA   \n",
       "24089  We study strong existence and pathwise uniquen...      NaN   \n",
       "\n",
       "      Organisme_UE Pays_ex adresse_UE  \\\n",
       "24088          NaN     NaN        NaN   \n",
       "24089          NaN     NaN        NaN   \n",
       "\n",
       "                              Organisme_Hors_UE Pays_ex_horsUE  \\\n",
       "24088                                       NaN            NaN   \n",
       "24089  Department of Mathematics [College Park]  United States   \n",
       "\n",
       "                                         adresse_hors_UE  \n",
       "24088                                                NaN  \n",
       "24089  4176 Campus Drive - William E. Kirwan Hall, Co...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  contrôle pour tests \n",
    "df_publis[df_publis[\"halID\"] == \"hal-00799242\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b0381c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 32958 lignes supprimées\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Supprimer les auteurs HORS INRIA qui ont à la fois une affiliation française et une affiliation étrangère)\n",
    "#########################################\n",
    "# Indicateurs\n",
    "df_publis[\"has_org\"] = df_publis[\"Organisme_UE\"].notna() | df_publis[\"Organisme_Hors_UE\"].notna()\n",
    "df_publis[\"has_no_acronyme\"] = df_publis[\"acronyme\"].isna() | (df_publis[\"acronyme\"].str.strip() == \"\")\n",
    "\n",
    "# Grouper par halID + Auteur\n",
    "grouped = df_publis.groupby([\"halID\", \"Auteur\"]).agg(\n",
    "    n_lignes=(\"halID\", \"count\"),          # nombre de lignes pour ce couple\n",
    "    has_no_acronyme=(\"has_no_acronyme\", \"any\"),\n",
    "    has_org=(\"has_org\", \"any\")\n",
    ").reset_index()\n",
    "\n",
    "# On garde uniquement ceux qui ont au moins 2 lignes et les deux cas\n",
    "auteurs_mixtes = grouped[\n",
    "    (grouped[\"n_lignes\"] >= 2) &\n",
    "    (grouped[\"has_no_acronyme\"]) &\n",
    "    (grouped[\"has_org\"])\n",
    "]\n",
    "\n",
    "# Supprimer ces auteurs de df_publis\n",
    "df_publis_clean = df_publis.merge(\n",
    "    auteurs_mixtes[[\"halID\", \"Auteur\"]],\n",
    "    on=[\"halID\", \"Auteur\"],\n",
    "    how=\"left\",\n",
    "    indicator=True\n",
    ")\n",
    "df_publis_clean = df_publis_clean[df_publis_clean[\"_merge\"] == \"left_only\"].drop(columns=\"_merge\")\n",
    "\n",
    "print(f\"✅ {len(df_publis) - len(df_publis_clean)} lignes supprimées\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3fb0b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "      <th>Organisme_UE</th>\n",
       "      <th>Pays_ex</th>\n",
       "      <th>adresse_UE</th>\n",
       "      <th>Organisme_Hors_UE</th>\n",
       "      <th>Pays_ex_horsUE</th>\n",
       "      <th>adresse_hors_UE</th>\n",
       "      <th>has_org</th>\n",
       "      <th>has_no_acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24088</th>\n",
       "      <td>hal-00799242</td>\n",
       "      <td>Champagnat, Nicolas</td>\n",
       "      <td>206068</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2018</td>\n",
       "      <td>pathwise uniqueness;rough drift;rough diffusio...</td>\n",
       "      <td>Mathematics [math]/Probability [math.PR]</td>\n",
       "      <td>We study strong existence and pathwise uniquen...</td>\n",
       "      <td>TOSCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24089</th>\n",
       "      <td>hal-00799242</td>\n",
       "      <td>Jabin, Pierre-Emmanuel</td>\n",
       "      <td>54156</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2018</td>\n",
       "      <td>pathwise uniqueness;rough drift;rough diffusio...</td>\n",
       "      <td>Mathematics [math]/Probability [math.PR]</td>\n",
       "      <td>We study strong existence and pathwise uniquen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Mathematics [College Park]</td>\n",
       "      <td>United States</td>\n",
       "      <td>4176 Campus Drive - William E. Kirwan Hall, Co...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              halID                  Auteur affiliation  Centre Annee  \\\n",
       "24088  hal-00799242     Champagnat, Nicolas      206068  Sophia  2018   \n",
       "24089  hal-00799242  Jabin, Pierre-Emmanuel       54156  Sophia  2018   \n",
       "\n",
       "                                                MotsCles  \\\n",
       "24088  pathwise uniqueness;rough drift;rough diffusio...   \n",
       "24089  pathwise uniqueness;rough drift;rough diffusio...   \n",
       "\n",
       "                                     Domaine(s)  \\\n",
       "24088  Mathematics [math]/Probability [math.PR]   \n",
       "24089  Mathematics [math]/Probability [math.PR]   \n",
       "\n",
       "                                                  Resume acronyme  \\\n",
       "24088  We study strong existence and pathwise uniquen...    TOSCA   \n",
       "24089  We study strong existence and pathwise uniquen...      NaN   \n",
       "\n",
       "      Organisme_UE Pays_ex adresse_UE  \\\n",
       "24088          NaN     NaN        NaN   \n",
       "24089          NaN     NaN        NaN   \n",
       "\n",
       "                              Organisme_Hors_UE Pays_ex_horsUE  \\\n",
       "24088                                       NaN            NaN   \n",
       "24089  Department of Mathematics [College Park]  United States   \n",
       "\n",
       "                                         adresse_hors_UE  has_org  \\\n",
       "24088                                                NaN    False   \n",
       "24089  4176 Campus Drive - William E. Kirwan Hall, Co...     True   \n",
       "\n",
       "       has_no_acronyme  \n",
       "24088            False  \n",
       "24089             True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrôle pour test \n",
    "df_publis_clean[df_publis_clean[\"halID\"] == \"hal-00799242\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf9e528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "      <th>Organisme_UE</th>\n",
       "      <th>Pays_ex</th>\n",
       "      <th>adresse_UE</th>\n",
       "      <th>Organisme_Hors_UE</th>\n",
       "      <th>Pays_ex_horsUE</th>\n",
       "      <th>adresse_hors_UE</th>\n",
       "      <th>has_org</th>\n",
       "      <th>has_no_acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25377</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Cabrera-Bosquet, Llorenç</td>\n",
       "      <td>37835</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25378</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Alvarez Prado, Santiago</td>\n",
       "      <td>37835</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25379</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Perez, Raphael</td>\n",
       "      <td>37835</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25380</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Artzet, Simon</td>\n",
       "      <td>37835</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25381</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Pradal, Christophe</td>\n",
       "      <td>141072</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>ZENITH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25382</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Coupel-Ledru, Aude</td>\n",
       "      <td>37835</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25383</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Fournier, Christian</td>\n",
       "      <td>37835</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25384</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Tardieu, Francois</td>\n",
       "      <td>37835</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              halID                    Auteur affiliation  Centre Annee  \\\n",
       "25377  hal-01895279  Cabrera-Bosquet, Llorenç       37835  Sophia  2019   \n",
       "25378  hal-01895279   Alvarez Prado, Santiago       37835  Sophia  2019   \n",
       "25379  hal-01895279            Perez, Raphael       37835  Sophia  2019   \n",
       "25380  hal-01895279             Artzet, Simon       37835  Sophia  2019   \n",
       "25381  hal-01895279        Pradal, Christophe      141072  Sophia  2019   \n",
       "25382  hal-01895279        Coupel-Ledru, Aude       37835  Sophia  2019   \n",
       "25383  hal-01895279       Fournier, Christian       37835  Sophia  2019   \n",
       "25384  hal-01895279         Tardieu, Francois       37835  Sophia  2019   \n",
       "\n",
       "                                                MotsCles  \\\n",
       "25377  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "25378  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "25379  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "25380  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "25381  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "25382  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "25383  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "25384  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "\n",
       "                                          Domaine(s)  \\\n",
       "25377  Computer Science [cs]/Modeling and Simulation   \n",
       "25378  Computer Science [cs]/Modeling and Simulation   \n",
       "25379  Computer Science [cs]/Modeling and Simulation   \n",
       "25380  Computer Science [cs]/Modeling and Simulation   \n",
       "25381  Computer Science [cs]/Modeling and Simulation   \n",
       "25382  Computer Science [cs]/Modeling and Simulation   \n",
       "25383  Computer Science [cs]/Modeling and Simulation   \n",
       "25384  Computer Science [cs]/Modeling and Simulation   \n",
       "\n",
       "                                                  Resume acronyme  \\\n",
       "25377  Multi-genotype canopies are frequent in phenot...      NaN   \n",
       "25378  Multi-genotype canopies are frequent in phenot...      NaN   \n",
       "25379  Multi-genotype canopies are frequent in phenot...      NaN   \n",
       "25380  Multi-genotype canopies are frequent in phenot...      NaN   \n",
       "25381  Multi-genotype canopies are frequent in phenot...   ZENITH   \n",
       "25382  Multi-genotype canopies are frequent in phenot...      NaN   \n",
       "25383  Multi-genotype canopies are frequent in phenot...      NaN   \n",
       "25384  Multi-genotype canopies are frequent in phenot...      NaN   \n",
       "\n",
       "      Organisme_UE Pays_ex adresse_UE Organisme_Hors_UE Pays_ex_horsUE  \\\n",
       "25377          NaN     NaN        NaN               NaN            NaN   \n",
       "25378          NaN     NaN        NaN               NaN            NaN   \n",
       "25379          NaN     NaN        NaN               NaN            NaN   \n",
       "25380          NaN     NaN        NaN               NaN            NaN   \n",
       "25381          NaN     NaN        NaN               NaN            NaN   \n",
       "25382          NaN     NaN        NaN               NaN            NaN   \n",
       "25383          NaN     NaN        NaN               NaN            NaN   \n",
       "25384          NaN     NaN        NaN               NaN            NaN   \n",
       "\n",
       "      adresse_hors_UE  has_org  has_no_acronyme  \n",
       "25377             NaN    False             True  \n",
       "25378             NaN    False             True  \n",
       "25379             NaN    False             True  \n",
       "25380             NaN    False             True  \n",
       "25381             NaN    False            False  \n",
       "25382             NaN    False             True  \n",
       "25383             NaN    False             True  \n",
       "25384             NaN    False             True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrôle pour test \n",
    "df_publis_clean[df_publis_clean[\"halID\"] == \"hal-01895279\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cefbfa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_publis = df_publis_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd359ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 28754 lignes supprimées\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage : On supprime tous les co-auteurs français = ne sont pas Inria (pas d'acronyme) et n'ont pas d'affiliations étrangères\n",
    "\n",
    "# Colonnes à tester pour le vide\n",
    "cols_to_check = [\"Organisme_UE\", \"Organisme_Hors_UE\", \"acronyme\"]\n",
    "\n",
    "# Masque des lignes vides\n",
    "mask_empty = df_publis[cols_to_check].apply(\n",
    "    lambda row: all(pd.isna(v) or str(v).strip() == \"\" for v in row),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# On garde seulement les lignes qui ne sont pas \"vides\"\n",
    "df_publis_clean = df_publis[~mask_empty].copy()\n",
    "\n",
    "print(f\"✅ {mask_empty.sum()} lignes supprimées\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa0baa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "      <th>Organisme_UE</th>\n",
       "      <th>Pays_ex</th>\n",
       "      <th>adresse_UE</th>\n",
       "      <th>Organisme_Hors_UE</th>\n",
       "      <th>Pays_ex_horsUE</th>\n",
       "      <th>adresse_hors_UE</th>\n",
       "      <th>has_org</th>\n",
       "      <th>has_no_acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25381</th>\n",
       "      <td>hal-01895279</td>\n",
       "      <td>Pradal, Christophe</td>\n",
       "      <td>141072</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>2019</td>\n",
       "      <td>Light use efficiency;Varietal mixture;Inter-ge...</td>\n",
       "      <td>Computer Science [cs]/Modeling and Simulation</td>\n",
       "      <td>Multi-genotype canopies are frequent in phenot...</td>\n",
       "      <td>ZENITH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              halID              Auteur affiliation  Centre Annee  \\\n",
       "25381  hal-01895279  Pradal, Christophe      141072  Sophia  2019   \n",
       "\n",
       "                                                MotsCles  \\\n",
       "25381  Light use efficiency;Varietal mixture;Inter-ge...   \n",
       "\n",
       "                                          Domaine(s)  \\\n",
       "25381  Computer Science [cs]/Modeling and Simulation   \n",
       "\n",
       "                                                  Resume acronyme  \\\n",
       "25381  Multi-genotype canopies are frequent in phenot...   ZENITH   \n",
       "\n",
       "      Organisme_UE Pays_ex adresse_UE Organisme_Hors_UE Pays_ex_horsUE  \\\n",
       "25381          NaN     NaN        NaN               NaN            NaN   \n",
       "\n",
       "      adresse_hors_UE  has_org  has_no_acronyme  \n",
       "25381             NaN    False            False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrôle pour test \n",
    "df_publis_clean[df_publis_clean[\"halID\"] == \"hal-01895279\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrôle pour test df_publis_clean[df_publis_clean[\"halID\"] == \"cea-04228169\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deedb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_publis = df_publis_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cef4a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "      <th>Organisme_UE</th>\n",
       "      <th>Pays_ex</th>\n",
       "      <th>adresse_UE</th>\n",
       "      <th>Organisme_Hors_UE</th>\n",
       "      <th>Pays_ex_horsUE</th>\n",
       "      <th>adresse_hors_UE</th>\n",
       "      <th>has_org</th>\n",
       "      <th>has_no_acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Soffer, Avy</td>\n",
       "      <td>452560</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Mathematics</td>\n",
       "      <td>United States</td>\n",
       "      <td>Hill Center for the Mathematical Sciences110 F...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Zhao, Xiaofei</td>\n",
       "      <td>525243</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "      <td>MINGUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Puy, Gilles</td>\n",
       "      <td>210613</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Tremblay, Nicolas</td>\n",
       "      <td>210613</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hal-01229578</td>\n",
       "      <td>Gribonval, Rémi</td>\n",
       "      <td>210613</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Sciences [physics]/Signal and Imag...</td>\n",
       "      <td>We study the problem of sampling k-bandlimited...</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          halID             Auteur affiliation  Centre Annee  \\\n",
       "0  hal-01328959        Soffer, Avy      452560  Rennes  2018   \n",
       "1  hal-01328959      Zhao, Xiaofei      525243  Rennes  2018   \n",
       "2  hal-01229578        Puy, Gilles      210613  Rennes  2018   \n",
       "3  hal-01229578  Tremblay, Nicolas      210613  Rennes  2018   \n",
       "4  hal-01229578    Gribonval, Rémi      210613  Rennes  2018   \n",
       "\n",
       "                                            MotsCles  \\\n",
       "0  vortex;radiation;modulation equations;numerica...   \n",
       "1  vortex;radiation;modulation equations;numerica...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                          Domaine(s)  \\\n",
       "0   Physics [physics]/Mathematical Physics [math-ph]   \n",
       "1   Physics [physics]/Mathematical Physics [math-ph]   \n",
       "2  Engineering Sciences [physics]/Signal and Imag...   \n",
       "3  Engineering Sciences [physics]/Signal and Imag...   \n",
       "4  Engineering Sciences [physics]/Signal and Imag...   \n",
       "\n",
       "                                              Resume acronyme Organisme_UE  \\\n",
       "0  We apply the modulation theory to study the vo...      NaN          NaN   \n",
       "1  We apply the modulation theory to study the vo...   MINGUS          NaN   \n",
       "2  We study the problem of sampling k-bandlimited...   PANAMA          NaN   \n",
       "3  We study the problem of sampling k-bandlimited...   PANAMA          NaN   \n",
       "4  We study the problem of sampling k-bandlimited...   PANAMA          NaN   \n",
       "\n",
       "  Pays_ex adresse_UE          Organisme_Hors_UE Pays_ex_horsUE  \\\n",
       "0     NaN        NaN  Department of Mathematics  United States   \n",
       "1     NaN        NaN                        NaN            NaN   \n",
       "2     NaN        NaN                        NaN            NaN   \n",
       "3     NaN        NaN                        NaN            NaN   \n",
       "4     NaN        NaN                        NaN            NaN   \n",
       "\n",
       "                                     adresse_hors_UE  has_org  has_no_acronyme  \n",
       "0  Hill Center for the Mathematical Sciences110 F...     True             True  \n",
       "1                                                NaN    False            False  \n",
       "2                                                NaN    False            False  \n",
       "3                                                NaN    False            False  \n",
       "4                                                NaN    False            False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_publis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c48a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde pas les publications avec juste un seul auteur\n",
    "df_publis_clean = df_publis[df_publis.groupby(\"halID\")[\"halID\"].transform(\"count\") > 1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a4fbaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "      <th>Organisme_UE</th>\n",
       "      <th>Pays_ex</th>\n",
       "      <th>adresse_UE</th>\n",
       "      <th>Organisme_Hors_UE</th>\n",
       "      <th>Pays_ex_horsUE</th>\n",
       "      <th>adresse_hors_UE</th>\n",
       "      <th>has_org</th>\n",
       "      <th>has_no_acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [halID, Auteur, affiliation, Centre, Annee, MotsCles, Domaine(s), Resume, acronyme, Organisme_UE, Pays_ex, adresse_UE, Organisme_Hors_UE, Pays_ex_horsUE, adresse_hors_UE, has_org, has_no_acronyme]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrôle pour test \n",
    "df_publis_clean[df_publis_clean[\"halID\"] == \"hal-01895279\"] # ne doit pas y être"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrôle pour test df_publis_clean[df_publis_clean[\"halID\"] == \"hal-05212970\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5afecece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_publis = df_publis_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be3c16ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>halID</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Annee</th>\n",
       "      <th>MotsCles</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Resume</th>\n",
       "      <th>acronyme</th>\n",
       "      <th>Organisme_UE</th>\n",
       "      <th>Pays_ex</th>\n",
       "      <th>adresse_UE</th>\n",
       "      <th>Organisme_Hors_UE</th>\n",
       "      <th>Pays_ex_horsUE</th>\n",
       "      <th>adresse_hors_UE</th>\n",
       "      <th>has_org</th>\n",
       "      <th>has_no_acronyme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Soffer, Avy</td>\n",
       "      <td>452560</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Department of Mathematics</td>\n",
       "      <td>United States</td>\n",
       "      <td>Hill Center for the Mathematical Sciences110 F...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hal-01328959</td>\n",
       "      <td>Zhao, Xiaofei</td>\n",
       "      <td>525243</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>2018</td>\n",
       "      <td>vortex;radiation;modulation equations;numerica...</td>\n",
       "      <td>Physics [physics]/Mathematical Physics [math-ph]</td>\n",
       "      <td>We apply the modulation theory to study the vo...</td>\n",
       "      <td>MINGUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          halID         Auteur affiliation  Centre Annee  \\\n",
       "0  hal-01328959    Soffer, Avy      452560  Rennes  2018   \n",
       "1  hal-01328959  Zhao, Xiaofei      525243  Rennes  2018   \n",
       "\n",
       "                                            MotsCles  \\\n",
       "0  vortex;radiation;modulation equations;numerica...   \n",
       "1  vortex;radiation;modulation equations;numerica...   \n",
       "\n",
       "                                         Domaine(s)  \\\n",
       "0  Physics [physics]/Mathematical Physics [math-ph]   \n",
       "1  Physics [physics]/Mathematical Physics [math-ph]   \n",
       "\n",
       "                                              Resume acronyme Organisme_UE  \\\n",
       "0  We apply the modulation theory to study the vo...      NaN          NaN   \n",
       "1  We apply the modulation theory to study the vo...   MINGUS          NaN   \n",
       "\n",
       "  Pays_ex adresse_UE          Organisme_Hors_UE Pays_ex_horsUE  \\\n",
       "0     NaN        NaN  Department of Mathematics  United States   \n",
       "1     NaN        NaN                        NaN            NaN   \n",
       "\n",
       "                                     adresse_hors_UE  has_org  has_no_acronyme  \n",
       "0  Hill Center for the Mathematical Sciences110 F...     True             True  \n",
       "1                                                NaN    False            False  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_publis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be216cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier Excel créé : Copubliants_par_auteur_Inria_tout.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Fichier final (1e partie) avec , pour chaque auteur Inria, les copubliants étrangers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. On part du df_publis et on isole les auteurs FR et étrangers\n",
    "auteurs_fr = df_publis[pd.notna(df_publis['acronyme']) & (df_publis['acronyme'].str.strip() != '')]\n",
    "auteurs_etr = df_publis[pd.isna(df_publis['acronyme']) | (df_publis['acronyme'].str.strip() == '')]\n",
    "\n",
    "# 2. Pour chaque auteur étranger, on veut rattacher les auteurs FR du même halID\n",
    "rows = []\n",
    "for _, row_etr in auteurs_etr.iterrows():\n",
    "    hal_id = row_etr['halID']\n",
    "    # Trouver les auteurs FR liés à ce halID\n",
    "    fr_list = auteurs_fr[auteurs_fr['halID'] == hal_id]\n",
    "    for _, row_fr in fr_list.iterrows():\n",
    "        rows.append({\n",
    "            'Equipe': row_fr['acronyme'],\n",
    "            'Centre':row_fr['Centre'],\n",
    "            'Auteurs FR': row_fr['Auteur'],\n",
    "            'Auteurs copubliants': row_etr['Auteur'],\n",
    "            'Organisme copubliant': row_etr['Organisme_Hors_UE'] if pd.notna(row_etr['Organisme_Hors_UE']) else row_etr['Organisme_UE'],\n",
    "            'Adresse': row_etr['adresse_hors_UE'] if pd.notna(row_etr['adresse_hors_UE']) else row_etr['adresse_UE'],\n",
    "            'Pays': row_etr['Pays_ex_horsUE'] if pd.notna(row_etr['Pays_ex_horsUE']) else row_etr['Pays_ex'],\n",
    "            'ID Aurehal': row_etr['affiliation'],\n",
    "            'Année': row_etr['Annee'],\n",
    "            'UE/Non UE': 'UE' if pd.notna(row_etr['Organisme_UE']) else 'Non UE',\n",
    "            'HalID': hal_id,\n",
    "            'Domaine(s)': row_etr['Domaine(s)'],\n",
    "            'Mots-cles' : row_etr['MotsCles'],\n",
    "            'Resume':row_etr['Resume'],\n",
    "        })\n",
    "\n",
    "# 3. Construire le DataFrame final\n",
    "df_final = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# 4. Trier par Equipe, Auteurs FR, Auteurs copubliants\n",
    "df_final = df_final.sort_values(by=['Equipe', 'Auteurs FR', 'Auteurs copubliants']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 5. Exporter vers Excel\n",
    "nom_du_fichier = f\"Copubliants_par_auteur_Inria_tout.xlsx\"\n",
    "df_final.to_excel(nom_du_fichier, index=False)\n",
    "\n",
    "print(f\"✅ Fichier Excel créé : {nom_du_fichier}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cb1a052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Equipe</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Auteurs FR</th>\n",
       "      <th>Auteurs copubliants</th>\n",
       "      <th>Organisme copubliant</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Pays</th>\n",
       "      <th>ID Aurehal</th>\n",
       "      <th>Année</th>\n",
       "      <th>UE/Non UE</th>\n",
       "      <th>HalID</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Mots-cles</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABS</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>Cazals, Frédéric</td>\n",
       "      <td>Agashe, Viraj</td>\n",
       "      <td>Indian Institute of Technology Delhi</td>\n",
       "      <td>Hauz Khas, New Delhi - 110 016. India</td>\n",
       "      <td>India</td>\n",
       "      <td>51173</td>\n",
       "      <td>2023</td>\n",
       "      <td>Non UE</td>\n",
       "      <td>hal-04366589</td>\n",
       "      <td>Computer Science [cs]/Bioinformatics [q-bio.QM]</td>\n",
       "      <td></td>\n",
       "      <td>Abstract Designing movesets providing high qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABS</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>Cazals, Frédéric</td>\n",
       "      <td>Bahar, Ivet</td>\n",
       "      <td>University of Pittsburgh</td>\n",
       "      <td>4200 Fifth Avenue Pittsburgh, PA 15260</td>\n",
       "      <td>United States</td>\n",
       "      <td>480689</td>\n",
       "      <td>2019</td>\n",
       "      <td>Non UE</td>\n",
       "      <td>hal-01968170</td>\n",
       "      <td>Computer Science [cs]/Computational Geometry [...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABS</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>Cazals, Frédéric</td>\n",
       "      <td>Carazo, José Maria</td>\n",
       "      <td>Centro Nacional de Biotecnología [Madrid]</td>\n",
       "      <td>Campus de la Universidad Autónoma de Madrid, 2...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>425523</td>\n",
       "      <td>2019</td>\n",
       "      <td>UE</td>\n",
       "      <td>hal-01968170</td>\n",
       "      <td>Computer Science [cs]/Computational Geometry [...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Equipe  Centre        Auteurs FR Auteurs copubliants  \\\n",
       "0    ABS  Sophia  Cazals, Frédéric       Agashe, Viraj   \n",
       "1    ABS  Sophia  Cazals, Frédéric         Bahar, Ivet   \n",
       "2    ABS  Sophia  Cazals, Frédéric  Carazo, José Maria   \n",
       "\n",
       "                        Organisme copubliant  \\\n",
       "0       Indian Institute of Technology Delhi   \n",
       "1                   University of Pittsburgh   \n",
       "2  Centro Nacional de Biotecnología [Madrid]   \n",
       "\n",
       "                                             Adresse           Pays  \\\n",
       "0              Hauz Khas, New Delhi - 110 016. India          India   \n",
       "1             4200 Fifth Avenue Pittsburgh, PA 15260  United States   \n",
       "2  Campus de la Universidad Autónoma de Madrid, 2...          Spain   \n",
       "\n",
       "  ID Aurehal Année UE/Non UE         HalID  \\\n",
       "0      51173  2023    Non UE  hal-04366589   \n",
       "1     480689  2019    Non UE  hal-01968170   \n",
       "2     425523  2019        UE  hal-01968170   \n",
       "\n",
       "                                          Domaine(s) Mots-cles  \\\n",
       "0    Computer Science [cs]/Bioinformatics [q-bio.QM]             \n",
       "1  Computer Science [cs]/Computational Geometry [...             \n",
       "2  Computer Science [cs]/Computational Geometry [...             \n",
       "\n",
       "                                              Resume  \n",
       "0  Abstract Designing movesets providing high qua...  \n",
       "1                                                     \n",
       "2                                                     "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrôle pour test df_final[df_final[\"HalID\"] == \"hal-00799242\"]\n",
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# décommenter la ligne suivante ligne si la librairie geotext n'est pas installée \n",
    "# pip install geotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc502f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copubliants_par_auteur_Inria_tout.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(nom_du_fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea289437",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Premier repérage des villes :\n",
    "#1 Utilisation du fichier contenant la liste déjà vérifiée des villes associées à un ID Aurehal = dictionnaire des villes aurehal\n",
    "\n",
    "#####################\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from geotext import GeoText\n",
    "import re\n",
    "\n",
    "df_publis_tout = \"\"\n",
    "###########################################\n",
    "# Chargement du fichier des copublications\n",
    "##########################################\n",
    "df_publis_tout = pd.read_excel(nom_du_fichier)\n",
    "\n",
    "\n",
    "#######################\n",
    "# Renseigner avec le dictionnaire déjà existant\n",
    "######################\n",
    "df_villes =\"\"\n",
    "# Chargement du fichier ID Aurehal - Ville\n",
    "df_villes = pd.read_excel(\"ID_Aurehal_Ville_Etat_Latitude_Longitude.xlsx\")\n",
    "\n",
    "\n",
    "# Fusionner les deux DataFrames sur la colonne ID_Aurehal\n",
    "df_publis_tout = df_publis_tout.merge(\n",
    "    df_villes[[\"ID_Aurehal\",\"Ville\",\"StateCode\", \"Latitude\", \"Longitude\",\"geonameid\"]],\n",
    "    left_on=\"ID Aurehal\", #nom de la colonne dans df_publis_tout\n",
    "    right_on=\"ID_Aurehal\",#nom de la colonne dans df_villes\n",
    "    how=\"left\"  # garde toutes les lignes de df_publis_tout, même si pas de correspondance\n",
    ")\n",
    "\n",
    "# Suppression de la colonne ID_Aurehal, qui ne nous sert plus\n",
    "df_publis_tout = df_publis_tout.drop(columns=[\"ID_Aurehal\"])\n",
    "\n",
    "df_publis_tout.to_excel(\"resultat_avec_villes_du_dictionnaire.xlsx\", index=False)\n",
    "\n",
    "# temps de traitement normal environ 20 secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb5ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Centre</th>\n",
       "      <th>Equipe</th>\n",
       "      <th>Auteurs FR</th>\n",
       "      <th>Auteurs copubliants</th>\n",
       "      <th>Organisme copubliant</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Ville</th>\n",
       "      <th>Pays</th>\n",
       "      <th>ID Aurehal</th>\n",
       "      <th>UE/Non UE</th>\n",
       "      <th>Année</th>\n",
       "      <th>HalID</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Mots-cles</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12277</th>\n",
       "      <td>Grenoble</td>\n",
       "      <td>DATAMOVE</td>\n",
       "      <td>Carastan-Santos, Danilo</td>\n",
       "      <td>Cordeiro, Daniel</td>\n",
       "      <td>Escola de Artes Ciências e Humanidades</td>\n",
       "      <td>Av. Arlindo Béttio, 1000 Ermelino Matarazzo Sã...</td>\n",
       "      <td>None</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>143207</td>\n",
       "      <td>Non UE</td>\n",
       "      <td>2025</td>\n",
       "      <td>hal-05212970</td>\n",
       "      <td>Computer Science [cs]/Distributed, Parallel, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This work presents a carbon footprint plugin d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12278</th>\n",
       "      <td>Grenoble</td>\n",
       "      <td>DATAMOVE</td>\n",
       "      <td>Carastan-Santos, Danilo</td>\n",
       "      <td>Mazzini Bruschi, Sarita</td>\n",
       "      <td>Instituto de Ciências Mathemàticas e de Comput...</td>\n",
       "      <td>Avenida Trabalhador São-carlense, 400 - Centro...</td>\n",
       "      <td>São Carlos</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>265913</td>\n",
       "      <td>Non UE</td>\n",
       "      <td>2025</td>\n",
       "      <td>hal-05212970</td>\n",
       "      <td>Computer Science [cs]/Distributed, Parallel, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This work presents a carbon footprint plugin d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12281</th>\n",
       "      <td>Grenoble</td>\n",
       "      <td>DATAMOVE</td>\n",
       "      <td>Carastan-Santos, Danilo</td>\n",
       "      <td>Saraiva, Gabriella</td>\n",
       "      <td>Escola de Artes Ciências e Humanidades</td>\n",
       "      <td>Av. Arlindo Béttio, 1000 Ermelino Matarazzo Sã...</td>\n",
       "      <td>None</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>143207</td>\n",
       "      <td>Non UE</td>\n",
       "      <td>2025</td>\n",
       "      <td>hal-05212970</td>\n",
       "      <td>Computer Science [cs]/Distributed, Parallel, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This work presents a carbon footprint plugin d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Centre    Equipe               Auteurs FR      Auteurs copubliants  \\\n",
       "12277  Grenoble  DATAMOVE  Carastan-Santos, Danilo         Cordeiro, Daniel   \n",
       "12278  Grenoble  DATAMOVE  Carastan-Santos, Danilo  Mazzini Bruschi, Sarita   \n",
       "12281  Grenoble  DATAMOVE  Carastan-Santos, Danilo       Saraiva, Gabriella   \n",
       "\n",
       "                                    Organisme copubliant  \\\n",
       "12277             Escola de Artes Ciências e Humanidades   \n",
       "12278  Instituto de Ciências Mathemàticas e de Comput...   \n",
       "12281             Escola de Artes Ciências e Humanidades   \n",
       "\n",
       "                                                 Adresse       Ville    Pays  \\\n",
       "12277  Av. Arlindo Béttio, 1000 Ermelino Matarazzo Sã...        None  Brazil   \n",
       "12278  Avenida Trabalhador São-carlense, 400 - Centro...  São Carlos  Brazil   \n",
       "12281  Av. Arlindo Béttio, 1000 Ermelino Matarazzo Sã...        None  Brazil   \n",
       "\n",
       "       ID Aurehal UE/Non UE  Année         HalID  \\\n",
       "12277      143207    Non UE   2025  hal-05212970   \n",
       "12278      265913    Non UE   2025  hal-05212970   \n",
       "12281      143207    Non UE   2025  hal-05212970   \n",
       "\n",
       "                                              Domaine(s) Mots-cles  \\\n",
       "12277  Computer Science [cs]/Distributed, Parallel, a...       NaN   \n",
       "12278  Computer Science [cs]/Distributed, Parallel, a...       NaN   \n",
       "12281  Computer Science [cs]/Distributed, Parallel, a...       NaN   \n",
       "\n",
       "                                                  Resume  Latitude  Longitude  \\\n",
       "12277  This work presents a carbon footprint plugin d...       NaN        NaN   \n",
       "12278  This work presents a carbon footprint plugin d...       NaN        NaN   \n",
       "12281  This work presents a carbon footprint plugin d...       NaN        NaN   \n",
       "\n",
       "       geonameid  \n",
       "12277        NaN  \n",
       "12278        NaN  \n",
       "12281        NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pour contrôle visuel, il doit y avoir un résultat pour cette référence\n",
    "df_publis_tout[df_publis_tout[\"HalID\"] == \"hal-05212970\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# 2e étape Identification des villes entre crochets dans le nom de l'organisme (il manquera encore la latitude et la longitude)\n",
    "################################################################################\n",
    "\n",
    "# Liste des pays à ignorer\n",
    "pays_a_ignorer = {\n",
    "    \"Algeria\", \"Argentina\", \"Australia\", \"Austria\", \"Belgium\", \"Bolivia\",\n",
    "    \"Bosnia and Herzegovina\", \"Brazil\", \"Brunei\", \"Bulgaria\", \"Burkina Faso\",\n",
    "    \"Cameroon\", \"Canada\", \"Chile\", \"China\", \"Colombia\", \"Costa Rica\", \"Croatia\",\n",
    "    \"Cyprus\", \"Czechia\", \"Denmark\", \"Ecuador\", \"Estonia\", \"Finland\", \"Georgia\",\n",
    "    \"Germany\", \"Greece\", \"Hong Kong\", \"Hungary\", \"Iceland\", \"India\", \"Indonesia\",\n",
    "    \"Iran\", \"Ireland\", \"Israel\", \"Italy\", \"Japan\", \"Jordan\", \"Kenya\", \"Latvia\",\n",
    "    \"Lebanon\", \"Lithuania\", \"Luxembourg\", \"Madagascar\", \"Malaysia\", \"Malta\",\n",
    "    \"Mexico\", \"Morocco\", \"Netherlands\", \"New Zealand\", \"Niger\", \"Nigeria\",\n",
    "    \"North Macedonia\", \"Norway\", \"Oman\", \"Pakistan\", \"Peru\", \"Poland\", \"Portugal\",\n",
    "    \"Romania\", \"Russia\", \"Saudi Arabia\", \"Senegal\", \"Serbia\", \"Singapore\",\n",
    "    \"Slovakia\", \"Slovenia\", \"South Africa\", \"South Korea\", \"Spain\", \"Sweden\",\n",
    "    \"Switzerland\", \"Taiwan\", \"Thailand\", \"Tunisia\", \"Turkey\", \"Uganda\", \"Ukraine\",\n",
    "    \"United Arab Emirates\", \"United Kingdom\", \"United States\", \"Uruguay\",\n",
    "    \"Venezuela\", \"Vietnam\"\n",
    "}\n",
    "\n",
    "# Fonction pour extraire la ville entre crochets\n",
    "def get_ville(organisme, adresse):\n",
    "    if isinstance(organisme, str):\n",
    "        match = re.search(r\"\\[(.*?)\\]\", organisme)\n",
    "        if match:\n",
    "            contenu = match.group(1).strip()\n",
    "            if contenu not in pays_a_ignorer:\n",
    "                return contenu\n",
    "    return None\n",
    "\n",
    "# Appliquer la fonction UNIQUEMENT si Ville est vide\n",
    "mask = df_publis_tout[\"Ville\"].isna() | (df_publis_tout[\"Ville\"] == \"\")\n",
    "df_publis_tout.loc[mask, \"Ville\"] = df_publis_tout[mask].apply(\n",
    "    lambda row: get_ville(row[\"Organisme copubliant\"], row[\"Adresse\"]), axis=1\n",
    ")\n",
    "\n",
    "# Créer un DataFrame avec les lignes où une ville a été extraite\n",
    "df_matches = df_publis_tout[df_publis_tout[\"Ville\"].notna() &\n",
    "                            (df_publis_tout[\"Ville\"] != \"\")].copy()\n",
    "\n",
    "# Garder uniquement les colonnes souhaitées et supprimer les doublons sur ID Aurehal\n",
    "df_matches = df_matches[[\"ID Aurehal\", \"Organisme copubliant\", \"Ville\"]].drop_duplicates(subset=[\"ID Aurehal\"])\n",
    "\n",
    "# Exporter la liste des ID avec Organisme copubliant et Ville\n",
    "# on ajoutera les latitudes et longitudes déjà connues\n",
    "# ensuite on vérifiera les inconnues pour voir si la ville est correctement identifiée\n",
    "df_matches.to_excel(\"id_aurehal_avec_ville_extraite.xlsx\", index=False)\n",
    "\n",
    "# Réordonner les colonnes si besoin\n",
    "cols_order = [\n",
    "    'Centre', 'Equipe', 'Auteurs FR', 'Auteurs copubliants', 'Organisme copubliant',\n",
    "    'Adresse', 'Ville', 'Pays', 'ID Aurehal', 'UE/Non UE', 'Année',\n",
    "    'HalID', 'Domaine(s)', 'Mots-cles', 'Resume',\"Latitude\", \"Longitude\",\"geonameid\"\n",
    "]\n",
    "if all(col in df_publis_tout.columns for col in cols_order):\n",
    "    df_publis_tout = df_publis_tout[cols_order]\n",
    "\n",
    "\n",
    "# Exporter le résultat principal\n",
    "df_publis_tout.to_excel(\"resultat_avec_villes_completes_dico_et_crochets.xlsx\", index=False)\n",
    "\n",
    "# Temps de traitement, environ 12 secondes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9980b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On renseigne la latitude et la longitude des villes déjà connues dans le dictionnaire de référence, parmi celles qui ont été trouvées entre crochets\n",
    "\n",
    "# On ne garde que le premier mot avant la virgule (ex: Richmond, UK --> Richmond)\n",
    "df_publis_tout[\"Ville\"] = df_publis_tout[\"Ville\"].str.split(\",\").str[0].str.strip()\n",
    "\n",
    "\n",
    "# Sélectionner les colonnes utiles dans df_villes\n",
    "df_villes_geo = \"\"\n",
    "df_publis_tout_geo = df_publis_tout\n",
    "\n",
    "df_villes_geo = df_villes[[\"Ville\", \"Pays\", \"Latitude\", \"Longitude\", \"geonameid\"]].drop_duplicates()\n",
    "\n",
    "# Fusionner avec df_publis_tout sur Ville et Pays\n",
    "df_temp = df_publis_tout_geo.merge(\n",
    "    df_villes_geo,\n",
    "    on=[\"Ville\", \"Pays\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_old\", \"_new\")\n",
    ")\n",
    "\n",
    "\n",
    "# Mettre à jour Latitude/Longitude uniquement si elles sont vides\n",
    "mask_lat = df_publis_tout_geo[\"Latitude\"].isna() & df_temp[\"Latitude_new\"].notna()\n",
    "mask_lon = df_publis_tout_geo[\"Longitude\"].isna() & df_temp[\"Longitude_new\"].notna()\n",
    "\n",
    "df_publis_tout_geo.loc[mask_lat, \"Latitude\"] = df_temp.loc[mask_lat, \"Latitude_new\"]\n",
    "df_publis_tout_geo.loc[mask_lon, \"Longitude\"] = df_temp.loc[mask_lon, \"Longitude_new\"]\n",
    "\n",
    "# mettre à jour geonameid si nécessaire\n",
    "if \"geonameid\" in df_publis_tout_geo.columns:\n",
    "    mask_geo = df_publis_tout_geo[\"geonameid\"].isna() & df_temp[\"geonameid_new\"].notna()\n",
    "    df_publis_tout_geo.loc[mask_geo, \"geonameid\"] = df_temp.loc[mask_geo, \"geonameid_new\"]\n",
    "\n",
    "\n",
    "# Exporter le résultat pour vérifier\n",
    "df_publis_tout_geo.to_excel(\"Copublis_Inria_villes_a_completer.xlsx\", index=False)\n",
    "\n",
    "# Temps de traitement environ 15 secondes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81713d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Centre</th>\n",
       "      <th>Equipe</th>\n",
       "      <th>Auteurs FR</th>\n",
       "      <th>Auteurs copubliants</th>\n",
       "      <th>Organisme copubliant</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Ville</th>\n",
       "      <th>Pays</th>\n",
       "      <th>ID Aurehal</th>\n",
       "      <th>UE/Non UE</th>\n",
       "      <th>Année</th>\n",
       "      <th>HalID</th>\n",
       "      <th>Domaine(s)</th>\n",
       "      <th>Mots-cles</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sophia</td>\n",
       "      <td>ABS</td>\n",
       "      <td>Mazauric, Dorian</td>\n",
       "      <td>Chaintreau, Augustin</td>\n",
       "      <td>Columbia University [New York]</td>\n",
       "      <td>Columbia University in the City of New York, 2...</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>75524</td>\n",
       "      <td>Non UE</td>\n",
       "      <td>2022</td>\n",
       "      <td>hal-03696264</td>\n",
       "      <td>Computer Science [cs]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We study a group-formation game on an undirect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Centre Equipe        Auteurs FR   Auteurs copubliants  \\\n",
       "27  Sophia    ABS  Mazauric, Dorian  Chaintreau, Augustin   \n",
       "\n",
       "              Organisme copubliant  \\\n",
       "27  Columbia University [New York]   \n",
       "\n",
       "                                              Adresse     Ville  \\\n",
       "27  Columbia University in the City of New York, 2...  New York   \n",
       "\n",
       "             Pays  ID Aurehal UE/Non UE  Année         HalID  \\\n",
       "27  United States       75524    Non UE   2022  hal-03696264   \n",
       "\n",
       "               Domaine(s) Mots-cles  \\\n",
       "27  Computer Science [cs]       NaN   \n",
       "\n",
       "                                               Resume  Latitude  Longitude  \\\n",
       "27  We study a group-formation game on an undirect...       NaN        NaN   \n",
       "\n",
       "    geonameid  \n",
       "27        NaN  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspection d'une référence pour contrôle visuel du résultat\n",
    "df_publis_tout_geo[df_publis_tout_geo[\"HalID\"] == \"hal-03696264\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae7e6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un fichier à part pour toutes les villes non trouvées\n",
    "\n",
    "df_villes_vides = \"\"\n",
    "# 1. Filtrer les lignes où Ville est vide\n",
    "df_villes_vides = df_publis_tout_geo[df_publis_tout_geo[\"Ville\"].isna()]\n",
    "\n",
    "# 2. Grouper et agréger\n",
    "df_villes_vides_uniques2 = df_villes_vides.groupby(\"ID Aurehal\").agg({\n",
    "    \"Organisme copubliant\": \"first\",\n",
    "    \"Adresse\": \"first\",\n",
    "    \"Pays\": \"first\",\n",
    "    \"HalID\": lambda x: \", \".join(x.unique())\n",
    "}).reset_index()\n",
    "\n",
    "# 3. Exporter\n",
    "df_villes_vides_uniques2.to_excel(\"villes_vides_uniques_aprs_dico_crochet_et_dico.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrôle visuel du résultat\n",
    "df.head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
